---
title : 操作系统
wiki: computer_basics
---

## 操作系统

### 什么是操作系统

操作系统是管理计算机硬件和软件资源的系统程序，本质上是一个运行在计算机上的软件程序 ，它为用户和应用程序提供统一的接口和运行环境，并且为用户提供了便捷的交互方式，使计算机系统高效、稳定、可用。

### **操作系统主要有哪些功能**

1. **进程和线程的管理**：进程的创建、撤销、阻塞、唤醒，进程间的通信等。
2. **存储管理**：内存和外存（磁盘等）的分配和管理等。
3. **文件管理**：文件的读、写、创建及删除等。
4. **设备管理**：设备（输入输出设备和外部存储设备等）的请求或释放以及启动等。
5. **网络管理**：管理计算机网络的配置、连接、通信和安全等。
6. **安全管理**：用户的身份认证、访问控制、文件加密等。



## 进程管理

### 进程，线程，协程

**进程**是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈，不与其他进程共享。进程间通信需要通过特定的机制，如管道、消息队列、信号量等。由于进程拥有独立的内存空间，因此其稳定性和安全性相对较高，但同时上下文切换的开销也较大，因为需要保存和恢复整个进程的状态。

**线程**是进程内的一个执行单元，也是CPU调度和分派的基本单位。与进程不同，线程共享进程的内存空间，包括堆和全局变量。线程之间通信更加高效，因为它们可以直接读写共享内存。线程的上下文切换开销较小，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。然而，由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。

**协程**是一种用户态的轻量级线程，是应用程序层面的概念，其调度完全由用户程序控制，而不需要内核的参与。另外它的调度方式不是线程那种抢占式的，而是协作式。协程的切换开销非常小，因为完全在用户态完成，本质上就是函数调用，而无需进行内核级的上下文切换。这使得协程在处理大量并发任务时具有非常高的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其编程模型更为复杂。

**进程与线程的关系**：进程是容器，线程是容器中的执行单元。线程必须依附于进程存在，离开进程线程无法单独存在。类似工人与工厂的关系。

### 进程切换和线程切换

**进程切换**：进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大。

**线程切换**：线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小。

**为什么线程切换比进程切换快**

线程切换比进程切换快是因为线程共享同一进程的地址空间和资源，线程切换时只需切换堆栈和程序计数器等少量信息，而不需要切换地址空间，避免了进程切换时需要切换内存映射表等大量资源的开销，从而节省了时间和系统资源。

### 进程有哪些状态

1. **就绪（Ready）**
   进程已具备运行条件，正在等待被 CPU 调度执行。
2. **运行（Running）**
   进程正在使用 CPU 执行指令，是唯一处于执行状态的进程（在单核系统中）。
3. **阻塞（Blocked）/等待（Waiting）**
   进程因等待某些事件（如 I/O 完成、资源可用）而暂停执行，即使有 CPU 也不能运行。
4. **新建（New）**
   进程正在被创建，尚未进入就绪队列。
5. **结束（Terminated）**
   进程已完成执行或被强制终止，正在释放资源。

### 进程上下文

**进程上下文**是进程在执行过程中某一时刻的状态的快照。它包含了操作系统为了能够**暂停当前进程并在之后准确地恢复它**所需要的所有信息。

它主要包含两大部分信息：

1. **CPU现场**：当时CPU各个寄存器的值（如程序计数器、栈指针等），这记录了进程执行到哪一步了。
2. **进程信息**：进程状态、内存管理信息（如页表）、打开的文件等资源清单。

**上下文切换的过程**就是保存当前进程的CPU状态到其PCB，切换内存空间，再从下一个进程的PCB中恢复其状态到CPU的过程。

### 进程间通信方式

进程间通信（IPC，Inter-Process Communication）是指不同进程之间交换数据的机制。

首先，最经典的**管道**。它分为两种：

1，**匿名管道**：这是一种单向通信 channel，只能在具有亲缘关系（如父子进程）的进程间使用。它的底层实现是内存中的一个缓冲区，数据遵循先进先出的原则。

2，**命名管道**：它解决了匿名管道亲缘关系的限制，通过一个文件系统中的命名管道文件，可以让任何无关的进程找到并进行通信。

第二，**消息队列**。它是由操作系统内核维护的一个消息链表。进程可以向队列中写入或读取特定格式和优先级的消息。与管道相比，它的优势在于可以按消息类型读取，而不必须是严格的先进先出，并且通信过程是异步的。

第三，**共享内存**。这是**最快**的一种IPC方式。它让多个进程将同一块物理内存映射到它们各自的虚拟地址空间中。这样，一个进程写入共享内存的数据，另一个进程立刻就能看到，省去了内核在中间拷贝数据的过程。但正因为这种直接的共享，通常需要配合**信号量**或**互斥锁**等同步机制来避免数据竞争。

第四，**信号量**。它本质上是一个计数器，主要用于进程间的同步与互斥，用来控制多个进程对共享资源的访问，避免出现竞态条件。它支持P（等待）和V（发送）两种原子操作。

最后，**Socket**。它最初是为网络通信设计的，但也可以用于同一台主机上的进程间通信。它功能强大，可以支持不同机器上的进程通信，是分布式系统的基础。

总结， 如果需要高性能且能处理同步问题，首选**共享内存**；如果只是简单的数据流传输，**管道**就足够；而**Socket**则提供了最广泛的跨机通信能力。

### 进程的调度算法

进程调度算法是操作系统决定哪个进程获得 CPU 执行权的策略。

首先，是**先来先服务调度算法**。顾名思义按照进程到达就绪队列的先后顺序进行调度。这是一种非抢占式的算法，实现简单且公平。但它的主要缺点是**不利于短作业**，因为如果一个长作业先到达，后面的短作业就需要等待很长时间，从而导致平均等待时间较长。

为了解决短作业等待时间长的问题，引入了**短作业优先调度算法**。它会优先选择预计运行时间最短的进程来执行。这个算法可以**最小化平均等待时间**，理论上是非抢占式算法中最优的。但它有一个明显的缺点：**可能导致长进程饥饿**，如果一直有短进程到达，长进程可能永远得不到执行。同时，它严重依赖于进程运行时间的准确性预测，而这在实际中是很难精确做到的。

为了平衡长短作业，并保证每个进程都能获得一定的CPU时间，引入了**时间片轮转调度算法**。这是为分时系统设计的、最经典的一种**抢占式**算法。系统会为每个进程分配一个固定的时间片。当一个进程的时间片用完后，它会被剥夺CPU并重新放回就绪队列的末尾，然后调度下一个进程。这种方式保证了**公平性和响应性**，但时间片大小的设置是关键：太小会导致频繁的上下文切换，开销过大；太大又会退化成先来先服务，影响响应速度。

接下来是**最高优先级调度算法**。它会选择优先级最高的进程优先执行。优先级可以静态指定，也可以动态调整。为了防止高优先级进程导致低优先级进程饥饿，通常可以结合**老化**技术，即随着低优先级进程等待时间的增加，逐步提高其优先级。这个算法的核心挑战在于如何公平合理地确定和调整优先级。

最后，是结合了上述多种算法思想的**多级反馈队列调度算法**。这被认为是**最通用、最综合**的一种算法，许多现代操作系统都以其为原型。它的核心设计是设立多个不同优先级的多级队列，每个队列拥有不同的时间片大小。新进程会先进入最高优先级的队列，如果它在一个时间片内没有执行完，就会被降级到下一个队列。下级队列的优先级更低，但分配的时间片更长。这样既能优先处理短作业（能在高优先级队列快速完成），又不会完全饿死长作业（最终会在低优先级大时间片的队列中得到执行）。

### 僵尸进程

**僵尸进程**是 **“死而不葬”** ，父进程还活着但失职，没有为其收尸（回收资源）。

具体指的是一个进程已经终止，但是其父进程尚未调用 `wait()`或 `waitpid()`系统调用来回收它，那么这个已死的子进程就成为了一个僵尸进程。

它几乎已经放弃所有内存空间，但是在内核的进程表中保留一个退出状态的条目，等待父进程读取。如果父进程一直不回收，僵尸进程的条目就会一直占用着进程号等系统资源。系统中存在少量僵尸进程影响不大，但如果大量产生且得不到清理，就会耗尽可用的进程号，导致系统无法创建新的进程。

**如何避免**：父进程应通过调用 `wait()`系列函数来主动回收子进程，或者可以捕获 `SIGCHLD`信号并在信号处理函数中进行异步回收。

### 孤儿进程

**孤儿进程**是 **“父死子活”** ，父进程先死了，但操作系统（init进程）会负责抚养它，并在它死后为其收尸，因此它本身不会造成问题。

具体指的是一个子进程的父进程先于它终止了，那么这个子进程就成为了一个孤儿进程。

为了解决孤儿进程无人回收的问题，操作系统有一个内置机制：**init进程（PID为1的进程）会自动成为所有孤儿进程的新父进程**。init进程会定期调用 `wait()`来回收这些孤儿进程的退出状态。因此，孤儿进程在结束后会被init进程自动清理，不会变成僵尸进程。

### 其他

{% folding child:codeblock open:false color:yellow 有了进程为什么还需要线程? %}

为了提高效率和改善程序结构。

1，线程创建和切换开销更小。

2，线程的通信和数据共享更简单，而进程间通信需要借助管道、消息队列等复杂机制，速度慢且麻烦。

3，多线程程序可以同时被调度到多个CPU核心上并行执行，从而更好地利用多核CPU。

{% endfolding %}



{% folding child:codeblock open:false color:red 为什么进程崩溃不会对其他进程产生很大影响? %}

1，进程的内存空间隔离：每个进程都有自己独立的内存空间，当一个进程崩溃时，其内存空间会被操作系统回收，不会影响其他进程的内存空间。

2，进程独立运行：进程之间不会共享资源。一个进程的崩溃通常不会对其他进程的资源产生影响。

{% endfolding %}



{% folding child:codeblock open:false color:blue 信号和信号量有什么区别? %}

1，信号：一种处理异步事件的方式。信号是比较复杂的通信方式，用于通知接收进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身

2，信号量：进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施，它负责协调各个线程，以保证它们能够正确，合理的使用公共资源。

{% endfolding %}



## 内存管理

内存管理是操作系统负责分配、回收和保护内存资源的一项核心功能，确保多个进程在使用内存时高效且互不干扰。

### 主要职责

1. **地址空间管理**：为每个进程分配独立的虚拟地址空间，并映射到物理内存，保障安全隔离。
2. **内存分配与回收**：按需为进程分配内存，在进程结束或释放时及时回收。
3. **内存保护**：防止进程非法访问不属于自己的内存区域。
4. **换页/置换管理**：当物理内存不足时，将不活跃数据暂存到磁盘（如交换空间），实现虚拟内存扩展。
5. **内存共享和重定位**：支持多个进程共享公共代码段，提高效率。

### 虚拟内存

>虚拟内存实现技术：
>
>1，分页机制：分页，分段，内存碎片
>
>2，按需调页：多级分页、快表
>
>3，页面置换：换页机制、缺页中断、交换空间、常见的页面置换算法

虚拟内存是操作系统内存管理的一项核心机制，它的主要目的是为每个进程提供一个**巨大、统一且安全**的虚拟地址空间。

它的核心思想是：**将进程的虚拟地址空间与实际的物理内存分离开来**。

**它通过以下三个主要技术来实现：**

1. **分页机制**：操作系统将进程的虚拟地址空间和物理内存都划分成固定大小的块（页和页框）。通过页表这个数据结构，来建立虚拟页到物理页框的映射关系。当一个进程访问它的虚拟内存时，由内存管理单元（MMU）和操作系统共同协作，通过查询页表来完成地址转换，找到实际的物理内存位置。
2. **按需调页**：这是虚拟内存高效工作的关键。进程开始执行时，并不会将其所有代码和数据都加载到物理内存中，而只是加载一小部分必要的页（如启动代码）。当进程尝试访问一个尚未加载到内存的页面时，会触发一个**缺页中断**。此时，操作系统的中断处理程序会被调用，负责从磁盘上将该页面**换入**物理内存，然后更新页表，最后再让进程继续执行刚才的访问指令。这个过程对应用程序是完全透明的。
3. **页面置换**：物理内存是有限的，当需要为新的页面腾出空间时，操作系统会使用特定的页面置换算法（如经典的LRU-最近最少使用算法）来选择“牺牲”一个旧的页面。如果这个旧页面被修改过（称为脏页），则需要先把它**换出**到磁盘上的交换空间，然后再将新的页面换入。

**虚拟内存带来了几个巨大的好处：**

1，**内存保护**：每个进程拥有独立的虚拟地址空间，一个进程无法直接访问另一个进程的内存，这极大地提升了系统的安全性和稳定性。

2，**简化编程**：程序员无需关心物理内存的具体布局和限制，只需在统一的、巨大的虚拟地址空间中进行编程。

3，**高效利用物理内存**：通过按需调页和页面置换，使得物理内存中只保留活跃的页面，从而可以运行比实际物理内存大得多的程序，实现了“小内存跑大程序”的效果。

#### 内存分页与页表

>分页就像集装箱仓库，仓库是页框，大小固定的集装箱是页，页表是映射关系。优点是可以轻松找到任何空位放入新集装箱，或者调换集装箱的位置，几乎不会产生“空货架”（外部碎片）。缺点是破坏了逻辑结构，比如说一段代码分散在几个不同的集装箱。

**内存分页**是一种内存管理方案。它将**进程的虚拟地址空间**划分为一系列固定大小的块，称为**页**。同时，将**物理内存**也划分为同样大小的块，称为**页框**。

**页表**是实现上述分页映射的**关键数据结构**。它是每个进程独有的。

**功能**：页表的每个条目记录了一个虚拟页号到物理页框号的映射关系，以及一些控制位。

**地址转换过程**：当进程访问一个虚拟地址时，CPU中的内存管理单元（MMU）会：

1. 将虚拟地址拆解为**虚拟页号**和**页内偏移量**。
2. 以虚拟页号为索引，去查询当前进程的页表，找到对应的页表项。
3. 从页表项中取出**物理页框号**。
4. 将**物理页框号**和原始的**页内偏移量**组合起来，得到最终的**物理地址**，从而完成访问。

**页表项中的控制位主要包括：**

- **存在位**：指示该页当前是否在物理内存中。如果不在（值为0），访问会触发一个**缺页中断**，操作系统需要将所需的页面从磁盘调入内存。
- **修改位**：指示该页内容是否被修改过。若被修改过，在页面被换出时需要进行写回磁盘操作。
- **访问权限位**：控制该页是否可读、可写、可执行，提供了内存保护的基础。

**优势：**

1. **内存保护**：每个进程有独立的页表，无法访问其他进程的物理内存。
2. **简化管理**：消除了外部碎片，物理内存得以高效利用。
3. **实现虚拟内存**：通过“存在位”和缺页中断，可以将暂时不用的页面换出到磁盘，使得进程可以运行在比实际物理内存大得多的虚拟地址空间上。

#### 内存分段与段表

>分段像逻辑货架仓库，仓库有不同型号大小不一的货架，比如“代码货架”、“数据货架”、“堆货架”、“栈货架”。优点是逻辑清晰，“xx货架存xx”，缺点是会产生空货架，小空间放不进大货架。

内存分段和段表是一种与分页不同的内存管理方案，它更侧重于反映程序的逻辑结构。

其核心思想是：**将一个程序的地址空间划分为若干个逻辑段**，每个段代表一个具有特定意义的连续内存区域，例如代码段、数据段、堆段、栈段等。这与分页的固定大小、物理划分有本质区别。

**分段的工作原理依赖于段表。**

**功能**：每个进程都有一个段表，它就像是这个进程的“分段地图”。段表中的每一个条目（段描述符）都记录了一个逻辑段的详细信息，主要包括：

1. **段基址**：该段在物理内存中的起始地址。
2. **段限长**：该段的最大长度，用于进行越界检查，保护内存安全。

**地址转换过程**：当CPU执行一条指令，访问一个逻辑地址（在分段中通常表示为 `<段号, 段内偏移量>`）时，会触发以下流程：

1. 以指令中提供的**段号**作为索引，去查找当前进程的段表，找到对应的段表项。
2. 将指令中提供的**段内偏移量**与段表项中的**段限长**进行比较。如果偏移量大于限长，则说明是一次非法访问，会触发一个段错误异常，从而实现了内存保护。
3. 若检查通过，则将**段基址**与**段内偏移量**相加，得到最终的**物理地址**。

**优势：**

1. **符合程序逻辑**：它天然地反映了程序员和编译器的视角，便于实现代码和数据的共享与保护。例如，可以将代码段设置为只读并在多个进程间共享。
2. **强大的内存保护**：每个段都有自己的权限（读、写、执行）和长度限制，任何越界或越权的访问都会被硬件立即检查并阻止。

**缺点：**

由于段的长度各不相同，并且在内存中不断被分配和回收，会在物理内存中产生大量不连续的小空闲区。也就是我们常说的**外部碎片**。

#### 内存碎片

**内存碎片**是指由于频繁的内存分配与释放，导致内存空间被分割成很多**无法有效利用的小块区域**，从而降低了内存使用效率。

根据位置不同，内存碎片分为两类：

1. **外部碎片**：指空闲内存被分散在不连续的区域中，虽然总空闲内存足够，但没有一块足够大的连续区域供分配。例如，有 100KB 空闲，但被分成多个 1~5KB 的小块，无法满足一个 30KB 的请求。
2. **内部碎片**：指实际分配给进程的内存大于其实际需要，未被使用的部分形成浪费。例如，申请 18 字节但系统按 32 字节对齐分配，剩余 14 字节就是内部碎片。

**产生原因**

主要是由于动态内存分配机制（如 malloc/free），以及不同大小内存块频繁申请与释放，导致内存空间不再连续。

**解决方式**

1，内存池（对象池）管理，避免频繁分配；

2，紧凑整理（如标记-整理算法）；

3，使用分页或分段机制，减少对连续内存的依赖。

#### 多级分页

>举例：学校里面，每个学生都有一页个人信息表放在档案室，单级分页是拿着全部学生的档案表查找，占用很大空间，并且很多学生已经毕业（内存未被使用），他们的记录也依然占着位置。多级分页是把学生根据年级划分，我需要大一的信息，我就去大一的档案室找，而不需要在意其他年级的档案。如果某个年级没有学生也不需要分配档案柜。核心思想在于“节省空间”和“按需分配”。

多级页表是一种为了解决单级页表**空间开销过大**问题而设计的优化方案。

它的核心思想是**按需分配**，通过引入页目录进行间接寻址，从而避免为整个虚拟地址空间创建完整的映射表。

本质上是时间换空间。

**优势**

1，**大幅节省内存**：这是最主要的目的。如果一个页表对应的整个虚拟地址区间都未被使用，那么只需在页目录中做一个“无效”标记，而根本不用分配整个页表所需的内存。这使得页表的内存开销与进程实际使用的虚拟内存大小成正比，而不是与整个虚拟地址空间的大小成正比。

2，**便于管理**：页目录和页表本身也可以被分页，方便操作系统进行内存管理。

**缺点**

**时间开销增加**：一次地址转换需要多次访问内存（访问N级页表就需要N+1次内存访问），降低了转换速度。这个缺点通常通过**TLB（快表）** 来极大地缓解。

#### 快表(TLB)

快表，全称是**转址旁路缓存**，它是一种专门用于加速虚拟地址到物理地址转换的**硬件缓存**。

设计思想有点像JIT(即时编译)，是为了解决多级页表地址转换过程中访问内存的次数增加导致的性能问题。

**工作原理**

1. **本质是缓存**：TLB是内存管理单元内部的一块高速缓存，它缓存了最近最常使用的**页表项**。您可以把它理解为页表的“热点数据缓存”。
2. **并行查找**：当CPU需要转换一个虚拟地址时，它会**同时**进行两个操作：
   - 将虚拟页号提交给TLB进行查找。
   - 启动常规的多级页表查询流程。
3. **高速命中**：如果TLB中存有该虚拟页号对应的页表项（称为**TLB命中**），硬件会立刻从TLB中获取到物理页框号，并**立刻终止**那个慢速的多级页表查询过程。这个操作非常快，通常只需要一个时钟周期。
4. **失效处理**：如果TLB中没有找到对应的项（称为**TLB未命中**），CPU就只能等待那个慢速的多级页表查询流程走完，来得到最终的物理地址。同时，它会将这次查询到的页表项**载入TLB**中，以备下次使用。如果TLB已满，则会使用一定的置换算法（如LRU）来淘汰一个旧条目。

#### 换页机制

>工作机制可以用一个图书馆的比喻来理解：
>
>1，**初始状态**：图书馆的书架（**物理内存**）空间有限，上面只存放着最热门的一些书籍（**活跃内存页**）。而绝大
>
>部分书籍都存放在后方的大仓库（**硬盘/交换空间**）里。
>
>2，**触发请求**：当您想借阅一本书时，会先去书架上查找。如果能直接找到（**内存命中**），就可以立即阅读，速度非常快。
>
>3，**处理缺货**：如果您发现书不在书架上（**缺页**），您会向管理员登记（**触发缺页中断**）。管理员（**操作系统**）会启动处理流程：他需要去仓库取书，但如果书架已满，他必须依据一套规则（**页面置换算法**，如“最近最少使用”）先决定将哪本书移回仓库（**换出**），以腾出空位。
>
>4，**完成调配**：管理员将新书从仓库取出放到书架上（**换入**），并更新图书目录（**更新页表**）。至此，您需要的书就触手可及了，借阅流程得以继续。

换页机制是实现虚拟内存的核心技术。它的核心思想是：并非将进程的所有页面都装入内存才能运行，而是允许进程的页在内存和磁盘之间动态地换入换出。

**其完整的工作流程**：

1. **初始加载与执行**：当一个进程启动时，操作系统只会为其加载最初几页必需的代码和数据（如入口代码），让进程先开始执行，而不会一次性加载全部内容。
2. **访问与缺页中断**：进程在执行过程中访问一条指令或数据。CPU中的内存管理单元（MMU）会尝试进行地址转换。如果发现目标页不在物理内存中（页表项标记为无效），MMU会立即触发一个**缺页中断**。
3. **中断处理与页面分配**：CPU接管控制权，切换到内核态。操作系统的缺页中断处理程序开始工作：它首先检查目标页面在磁盘上的位置。随后，处理程序会尝试在物理内存中为其分配一个空闲的页框。
4. **页面置换（核心决策）**：如果此时物理内存已满，没有空闲页框，操作系统就必须启动**页面置换算法**（如LRU、时钟算法等）。该算法会根据特定策略，从当前内存中的所有页面中选择一个“牺牲”页面。
5. **换出操作**：如果被选中的“牺牲”页面在内存期间被修改过（是一个“脏页”），操作系统需要先将它**写回到磁盘**的交换空间中，以确保数据持久化。
6. **换入操作与映射更新**：然后，操作系统将进程所需要的目标页面**从磁盘**加载到刚刚腾出的物理页框中。随后，它**更新页表**，建立新的虚拟页到物理页框的映射关系，并将该页表项标记为有效。
7. **恢复执行**：最后，操作系统恢复被中断的进程的现场，并重新执行那条引发缺页的指令。此次，该指令便能成功访问内存，进程得以继续运行。

**换页机制优势：**

- **内存超载**：它使得应用程序可以运行在比实际物理内存大得多的虚拟地址空间上。
- **高效利用内存**：物理内存中只保留活跃的页面，避免了闲置数据长期占用宝贵的内存资源。
- **简化编程与内存管理**：为程序员提供了巨大的、连续且统一的地址空间，无需手动管理数据的覆盖和交换。

总而言之，换页机制通过软硬件协同，以**缺页中断为驱动**，以**页面置换算法为决策核心**，透明地在内存和磁盘之间交换数据，是虚拟内存得以实现的基石。

#### 缺页中断

它是一个由硬件自动检测并发起的信号，是CPU通知操作系统“所需资源不在位”的标准机制，是整个换页流程的发起者和驱动者。

#### 交换空间

它是操作系统在**硬盘**上预留的一块特殊区域。它的核心作用是**扩展物理内存**，充当内存的“溢出缓冲区”或“后备仓库”，是虚拟内存系统得以实现的物理基础。

#### 常见的页面置换算法

页面置换算法是虚拟内存管理的核心组件，当发生缺页中断且物理内存已满时，操作系统必须选择一个页面将其换出到磁盘，以便为新页面腾出空间。选择哪个页面的策略，就是页面置换算法。其目标是尽可能减少后续的缺页次数。

常见的页面置换算法主要有以下四种：

首先，是最简单的**理想置换算法**。这是一种理论上的算法，无法实际实现。它的策略是选择**在未来最长时间内不再被访问**的页面进行淘汰。虽然无法实现，但它为衡量其他算法的效率提供了一个最优 benchmark，可以用来判断其他算法的好坏。

第二，是**先进先出算法**。它的策略是选择**最早调入内存**的页面进行淘汰。实现非常简单，只需要维护一个队列。但它固有的缺点是：可能会淘汰掉一些虽然较早进入但仍在被频繁访问的页面（比如一个初始化后一直使用的核心库），而且会出现一种反常现象，即分配更多的页框给进程，有时反而会导致缺页率上升。

第三，是**最近最久未使用算法**。这是最著名且高效的算法之一。它的策略是选择**最长时间没有被访问**的页面进行淘汰。LRU 算法的理念符合程序的局部性原理，性能接近理想算法，效果非常好。但它的挑战在于**实现开销较大**。为了实现它，需要在每次访问内存时都更新数据结构（如链表或栈），或者借助硬件的“访问位”来近似实现，这带来了不小的开销。

正因为 LRU 的实现开销大，实践中产生了它的一个近似算法，称为**时钟算法**。时钟算法是 LRU 和 FIFO 的一个折衷。它维护一个类似钟面的环形链表，并利用页表项中的“访问位”。当需要置换时，指针顺时针扫描，如果遇到访问位为 1 的页面，就将其置为 0 并跳过；如果遇到访问位为 0 的页面，就选择它进行置换。这个过程就像时钟的指针在循环扫描。它在保持了接近 LRU 性能的同时，大大降低了实现的开销。

**总结来说，** 选择哪种算法是一种权衡：OPT 是理想标杆，FIFO 简单但性能不佳，LRU 性能优异但实现复杂，而时钟算法则是实践中在性能和开销之间一个非常好的平衡选择。

### 共享内存

**共享内存**是允许两个或多个进程**直接读写同一块物理内存区域**的IPC（进程间通信）方式。它是**最快**的一种IPC机制，因为数据不需要在内核和用户空间之间来回拷贝。

**优点**：

- **极速**：避免了数据拷贝，是最快的IPC。
- **自然**：使用方式与操作普通内存无异，非常方便。

**缺点与挑战**：

- **需要同步**：这是共享内存最大的挑战。多个进程同时读写同一块内存会导致**竞态条件**。必须使用**同步机制**（如**信号量**、**互斥锁**或**文件锁**）来保护共享内存，确保数据的一致性。
- **生命周期管理**：共享内存段是独立于进程的。即使所有进程都崩溃了，共享内存段可能依然存在于内核中，需要手动清理（使用 `ipcrm`命令）。

---

**底层原理（内存映射）**

这背后的魔法是**虚拟内存**和**页表**。

- 每个进程都有自己的虚拟地址空间和页表，页表负责将虚拟地址映射到物理地址。
- 当进程A和进程B都附加到同一块共享内存时，它们的页表中，**不同的虚拟地址页面**被映射到了**相同的物理内存帧**上。
- 进程A写入其虚拟地址 `0x1234`，通过页表转换，实际是写入了物理地址 `0xAAAA`。
- 进程B读取其虚拟地址 `0x5678`，通过页表转换，实际是从物理地址 `0xAAAA`读取。
- 这样，两个进程就通过共享的物理内存 `0xAAAA`实现了通信。

### 其他

{% folding child:codeblock open:false color:red 程序的内存布局? %}

一个程序在运行时，其内存布局从低地址到高地址大致排列如下：

1. **代码段**：也称为文本段。它存放的是**程序的机器指令**，是只读的，防止程序意外修改自身的指令。这块内存通常可以被多个进程实例共享。
2. **数据段**：它包含了**已初始化的全局变量和静态变量**。例如，在函数外声明的 `int global_var = 100;`就存储在这里。程序加载时，这些变量就从可执行文件中读取到了内存中。
3. **BSS 段**：存放**未初始化的全局变量和静态变量**。例如 `static int uninit_var;`。BSS段在程序开始运行时会被操作系统**自动初始化为零**。将已初始化和未初始化的数据分开，可以节省磁盘空间——可执行文件无需记录未初始化变量的大量零值，只需记录它们的大小即可。
4. **堆**：用于**动态内存分配**。当程序使用 `malloc()`, `calloc()`, `new`等函数时，内存就从这里分配。堆内存的**生命周期由程序员控制**（手动分配和释放），如果管理不善会导致内存泄漏。堆的地址空间是**向上增长**的。
5. **内存映射段**：这里通常映射了**共享库**（如C标准库 `libc.so`）以及用户通过 `mmap`系统调用映射的文件或匿名内存。
6. **栈**：用于存放**局部变量**、**函数参数**以及**函数调用的上下文**（如返回地址、寄存器保存值）。每次函数调用都会在栈上分配一个新的**栈帧**。栈的地址空间是**向下增长**的。它的分配和回收由编译器自动管理，速度极快。需要注意的是，栈空间通常是有限的，过度递归或分配大块局部变量会导致**栈溢出**。
7. **内核空间**：地址空间的最高部分（通常最顶部的1GB）是为**内核保留**的。它存放操作系统内核的代码、数据和每个进程的内核栈。用户程序无法直接访问，必须通过系统调用陷入内核模式才能访问。

{% endfolding %}



{% folding child:codeblock open:false color:orange 堆和栈的区别? %}

**分配方式**：堆是动态分配内存，由程序员手动申请和释放内存，通常用于存储动态数据结构和对象。栈是静态分配内存，由编译器自动分配和释放内存，用于存储函数的局部变量和函数调用信息。

**内存管理**：堆需要程序员手动管理内存的分配和释放，如果管理不当可能会导致内存泄漏或内存溢出。栈由编译器自动管理内存，遵循后进先出的原则，变量的生命周期由其作用域决定，函数调用时分配内存，函数返回时释放内存。

**大小和速度**：堆通常比栈大，内存空间较大，动态分配和释放内存需要时间开销。栈大小有限，通常比较小，内存分配和释放速度较快，因为是编译器自动管理。

{% endfolding %}



{% folding child:codeblock open:false color:yellow 分段和分页的区别? %}

1，段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。

2，段的大小不固定，有它所完成的功能决定；页的大小固定，由系统决定

3，段向用户提供二维地址空间；页向用户提供的是一维地址空间

4，段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。

{% endfolding %}



{% folding child:codeblock open:false color:green 内存管理方式 %}

**内存管理方式是操作系统为实现高效、灵活、安全地分配和回收内存资源而采用的策略，常见的方式主要有以下几种：**

1. **连续分配管理**
   最早期的方式，将进程分配到一块连续的物理内存区域，包括静态分区和动态分区。
   - 优点：简单、访问快；
   - 缺点：容易产生**外部碎片**，不易扩展。
2. **分页（Paging）**
   把虚拟内存和物理内存划分成固定大小的页（Page）和页框（Frame），通过页表实现地址映射。
   - 优点：消除了外部碎片，支持虚拟内存；
   - 缺点：可能出现**内部碎片**，且多级页表会增加访问开销。
3. **分段（Segmentation）**
   将程序划分为逻辑段（如代码段、数据段、栈段等），每段可以大小不同，独立分配内存。
   - 优点：更符合程序逻辑结构，利于保护和共享；
   - 缺点：仍可能有**外部碎片**，实现比分页复杂。
4. **段页式管理（Segmented Paging）**
   结合分页和分段的优点，每个段再分页，兼顾逻辑结构和物理管理效率，是现代操作系统常用方式。
   - 优点：灵活、可扩展，支持大空间管理；
   - 缺点：地址转换复杂，依赖硬件支持。

{% endfolding %}



{% folding child:codeblock open:false color:blue 操作系统内存不足的时候会发生什么？ %}

当操作系统内存不足时，并不会立即导致程序崩溃或系统卡死。现代操作系统设计了一整套复杂而有效的机制来应对和管理这种情况，主要会发生以下几件事情：

**1. 触发页面交换（到Swap空间）**

这是最核心的应对机制。操作系统会识别出一部分最近不常用的**匿名内存页**（比如堆、栈中的数据），将它们从物理内存**换出**到磁盘上专门的**交换分区** 或**交换文件**中，从而腾出物理内存空间给急需的进程使用。这个过程对应用程序是透明的，但当应用程序之后访问被换出的页面时，会触发一个**缺页异常**，操作系统需要再把它从磁盘**换入**内存，这会导致明显的性能下降，我们能感觉到系统变‘卡’。

**2. 回收缓存和缓冲区**

Linux等系统会充分利用空闲内存来作为磁盘缓存（Page Cache）和缓冲区，以提升IO性能。当内存紧张时，操作系统会**优先回收这些缓存和缓冲区**的内存。因为回收这些只是可能降低IO速度，而不会影响应用程序的正确性。所以我们会看到系统的可用内存变多，但缓存减少。

**3. OOM Killer被触发（最后手段）**

如果即使进行了大量交换和缓存回收，系统依然面临严重的内存耗尽危机，Linux内核的**OOM Killer**机制就会被激活。它的职责是选择一个‘最佳’进程并将其杀死，从而立即释放它占用的所有内存资源，挽救整个系统。

OOM Killer的选择并非随机，它基于一个复杂的算法给所有进程打分（`oom_score`），主要考虑：

- **内存占用**：占用物理内存越多，分数越高。
- **进程价值**：root用户进程、运行时间长的进程、重要的守护进程分数会偏低。
- **子进程负担**：如果一个进程有很多子进程且都消耗大量内存，父进程的分数会增高。

**4. 系统层面的症状表现**

从用户和程序员的角度，会观察到：

- **系统响应极其缓慢**：由于频繁的页面交换（颠簸），硬盘灯常亮，CPU大部分时间在等待IO。
- **应用程序可能因分配不到内存而`malloc`失败**：返回`NULL`。
- **应用程序可能被强制终止**：如果你发现一个进程突然不见了，并且系统日志（`/var/log/messages`或`dmesg`）里有OOM Killer的记录，那就是它干的。

**总结来说，操作系统应对内存不足是一个渐进的过程：先是用性能换空间（交换和回收缓存），最后不得已才用稳定性换生存（杀死进程）。理解这个过程对于诊断线上服务器的内存问题至关重要。**

{% endfolding %}



## 文件系统

文件系统主要负责管理和组织计算机存储设备上的文件和目录。

### 功能

1. **存储管理**：将文件数据存储到物理存储介质中，并且管理空间分配。
2. **文件管理**：文件的创建、删除、移动、重命名、压缩、加密、共享等等。
3. **目录管理**：目录的创建、删除、移动、重命名等等。
4. **文件访问控制**：管理不同用户或进程对文件的访问权限。

### 提高文件系统性能的方式

- **优化硬件**：使用高速硬件设备（如 SSD、NVMe）替代传统的机械硬盘，使用 RAID（Redundant Array of Inexpensive Disks）等技术提高磁盘性能。
- **选择合适的文件系统选型**：不同的文件系统具有不同的特性，对于不同的应用场景选择合适的文件系统可以提高系统性能。
- **运用缓存**：访问磁盘的效率比较低，可以运用缓存来减少磁盘的访问次数。不过，需要注意缓存命中率，缓存命中率过低的话，效果太差。
- **避免磁盘过度使用**：注意磁盘的使用率，避免将磁盘用满，尽量留一些剩余空间，以免对文件系统的性能产生负面影响。
- **对磁盘进行合理的分区**：合理的磁盘分区方案，能够使文件系统在不同的区域存储文件，从而减少文件碎片，提高文件读写性能。

### 常见的磁盘调度算法

**先来先服务（FCFS, First-Come First-Served）**
 按照请求到达的顺序依次处理，简单但可能导致大量磁头移动，效率较低。

**最短寻道时间优先（SSTF, Shortest Seek Time First）**
 优先处理距离当前磁头位置最近的请求，减少总磁头移动距离，但可能导致远处请求长时间得不到处理（“饥饿”）。

**扫描算法（SCAN，也称电梯算法）**
 磁头按一个方向移动，处理沿途请求，直到边界后再反向移动处理另一方向的请求，类似电梯运行。

**循环扫描算法（C-SCAN）**
 磁头只向一个方向处理请求，到达边界后直接返回起始端重新开始扫描，避免中间区域请求过度集中处理。

**LOOK 和 C-LOOK 算法**
 是对 SCAN 和 C-SCAN 的优化：磁头只扫描到最后一个请求的位置而不是固定边界，减少不必要移动。

### 硬链接和软链接

>硬链接像一个人有多个外号，无论你用哪个外号称呼他，指的都是同一个人。这个人（文件数据）不会因为一个名字不用了而消失。
>
>软链接像一个快捷方式。

**硬链接**：本质是为同一个文件数据块创建多个目录条目。它直接指向文件的 **inode**（索引节点）。它不能跨越文件系统，也不能对目录进行链接。

1，原始文件删除后，只要还有一个硬链接存在，文件数据就不会被真正删除

2，所有硬链接都是平等的，没有主次之分。它们只是同一个inode的不同名字。

3，修改任何一个硬链接的内容，所有链接看到的内容都会同步改变，因为它们访问的是同一份数据。

**软链接**：本质是一个特殊的文件，这个文件的内容是另一个文件的路径名。有独⽴的 **inode**。能跨越文件系统。

1，⽬标⽂件被删除了，链接⽂件还是在的，只不过打不开指向的文件了而已。

**硬链接为什么不能跨文件系统**

硬链接是通过 inode 节点号建立连接的，而硬链接和源文件共享相同的 inode 节点号。

然而，每个文件系统都有自己的独立 inode 表，且每个 inode 表只维护该文件系统内的 inode。如果在不同的文件系统之间创建硬链接，可能会导致 inode 节点号冲突的问题，即目标文件的 inode 节点号已经在该文件系统中被使用。

## 中断

中断是CPU响应外部事件的一种机制，它允许CPU暂停当前正在执行的程序，转而去处理外部设备发出的紧急请求或内部CPU产生的异常事件，处理完毕后又能恢复原来程序的执行。

### 类型

中断主要可以分为两大类：**外部中断**和**内部中断**。

**1，外部中断（硬件中断）**

这类中断由**CPU外部的硬件设备**发起，通过中断信号线通知CPU。它通常是**异步**的，意味着中断请求的到来与CPU正在执行的指令无关。

- **可屏蔽中断**：大部分由外部I/O设备产生，如网卡接收到数据包、硬盘完成数据读写、键盘被敲击、定时器到期等。
  - **特点**：CPU可以通过设置**中断屏蔽位**（如IF标志位）来暂时忽略这些中断请求。这用于保护重要的、不希望被打断的代码段（临界区）。
- **不可屏蔽中断**：通常用于处理非常紧急的硬件故障，如电源掉电、内存校验错误等。
  - **特点**：**CPU必须立即响应**，无法通过软件指令屏蔽。这是最高优先级的中断。

**2，内部中断（软件中断）**

这类中断由**CPU内部在执行指令时**根据代码执行情况自动触发，是**同步**的，即它的发生一定是由正在执行的某条指令导致的。

- **陷阱**：**有意**安排的，用于实现系统功能调用或调试。执行后，CPU会记录下一条指令的地址（以便返回）。比如：应用程序调用 `printf`函数，最终会通过一条类似于 `int 0x80`或 `syscall`的指令陷入内核，这就是一种陷阱。调试时的断点也是陷阱。
- **故障**：是一种**可修复**的错误。CPU在执行指令**前**检测到异常条件，触发中断。处理完后，CPU会**重新执行**刚才那条出错的指令。比如：**缺页异常**是最典型的故障。当访问的页面不在内存中时，CPU触发缺页中断；操作系统将页面从磁盘调入后，再让CPU重新执行那条访问内存的指令，这次就能成功了。
- **终止**：处理**不可修复**的严重错误。CPU在执行指令**后**检测到致命错误，无法恢复，通常只能强制终止当前程序。比如：硬件故障、非法指令、系统数据结构被破坏（如Linux中的 Kernel Panic）。

### 流程

1. **​中断触发​**​：硬件或软件发出中断信号。
2. **保护现场**：CPU自动保存当前程序的上下文（如程序计数器、寄存器状态）。
3. **识别与寻址**：CPU获取一个称为“中断向量”的号码，并据此在“中断描述符表”中找到对应的中断处理程序入口地址。
4. **执行处理程序**：CPU切换到内核态，执行相应的中断服务例程。
5. **恢复现场**：中断处理完毕后，CPU恢复之前保存的现场，继续执行被中断的程序。

### 作用

1. **实现CPU与I/O设备的并行工作（提高CPU利用率）**

   最重要的作用。让CPU不需要**轮询**来检查设备状态，提供了CPU利用率，使得CPU和I/O设备可以真正地并行工作，极大地提升了CPU的利用率和系统整体的吞吐量。

2. **处理异常事件，保证系统稳定运行**

   CPU在执行过程中会遇到各种无法预料的错误，如除零、非法指令、缺页等。中断机制为这些异常事件提供了统一的处理入口。当发生异常时，CPU会自动切换到操作系统内核预设的处理程序，从而可以优雅地报告错误、修复问题（如调入缺失的页面）或终止进程，避免了系统崩溃，保障了系统的稳定性和可靠性。

3. **提供用户程序与操作系统内核的接口（系统调用）**

   应用程序没有权限直接操作硬件或执行特权指令。它需要通过一种方式请求操作系统为其服务。**系统调用**就是通过触发一个软中断（例如Linux的`int 0x80`或`syscall`指令）来实现的。这使CPU从用户态切换到内核态，由操作系统内核完成请求后，再返回用户态。中断机制是实现操作系统的**保护性**和**隔离性**的关键。

4. **满足实时处理需求**

   对于需要及时响应外部事件的系统（如工业控制、嵌入式设备），中断提供了一种**异步**的响应机制。高优先级的事件可以随时打断当前任务，得到CPU的立即处理，从而满足严格的实时性要求。

---

## 网络IO

### 零拷贝

零拷贝是一种用于提升I/O性能的关键技术，它的核心目标是**减少甚至完全避免数据在内存中的不必要的拷贝次数**，从而降低CPU开销和上下文切换，显著提升吞吐量。

**1. 传统方式的瓶颈：**

以‘服务器发送文件’这个经典场景为例。传统方式下，数据需要经历：

- `read`调用：数据从**磁盘**->**内核缓冲区**->**用户缓冲区**（1次拷贝）。

- `write`调用：数据从**用户缓冲区**->**套接字缓冲区**（第2次拷贝）。

  最后再从**套接字缓冲区**送到网卡。

  这个过程涉及**4次上下文切换**和**2次CPU数据拷贝**，效率很低。

**2. 零拷贝的解决方案：**

Linux主要通过 `sendfile`系统调用实现零拷贝。它允许数据直接在**内核缓冲区**和**套接字缓冲区**之间传输，**完全绕过了用户空间**。这样就将拷贝次数从2次减少到了1次（仅内核内拷贝）。

**3. 真正的‘零’拷贝：**

在支持**Scatter-Gather DMA**的网卡控制器上，可以做到真正的零拷贝。`sendfile`调用时，内核不再拷贝数据本身，而是将数据在内存中的**地址和长度信息**（描述符）直接发给网卡。之后，网卡的DMA引擎会**根据这些描述符，直接从内核缓冲区读取数据并发送**。整个过程**完全不需要CPU参与数据搬运**。

这也是Nginx、Kafka等高性能中间件能够实现极高吞吐量的核心技术之一。

### IO模型有哪些

I/O模型主要分为五种，区别在于应用程序在**等待数据就绪**和**数据拷贝**这两个阶段的行为不同。

1. **阻塞I/O**：最传统的方式。应用程序调用I/O操作后，线程会一直挂起等待，直到数据完全准备好并从内核拷贝到用户空间。**简单，但性能差**，一个线程只能处理一个连接。
2. **非阻塞I/O**：应用程序调用I/O操作后，如果数据没准备好，会立刻返回一个状态码。线程需要通过**不断轮询**来检查数据是否就绪，在拷贝数据时依然会阻塞。**避免了线程挂起，但轮询消耗大量CPU**。
3. **I/O多路复用**：这是**高并发编程的基石**。应用程序将多个I/O请求注册到一个多路复用器（如`select`, `epoll`），然后阻塞在这个复用器上。当任何一个请求的数据就绪时，复用器返回通知，应用程序再逐个处理。**核心优势是一个线程可以高效地管理成千上万个连接**。
4. **信号驱动I/O**：应用程序在发起I/O请求后就可以继续执行。当数据就绪时，内核会发送一个信号来通知应用程序，随后应用程序再进行数据拷贝（该阶段阻塞）。**通知机制是异步的，但拷贝仍是同步的**，实践中较少使用。
5. **异步I/O**：**真正的异步模型**。应用程序发起I/O请求后立即返回，内核会负责完成从等待数据到数据拷贝的所有工作。完成后，内核通过回调等方式通知应用程序。**应用程序在两个阶段都不会被阻塞**。

---

前四种模型（阻塞、非阻塞、多路复用、信号驱动）都属于**同步I/O**，因为真正的I/O读写操作都会在某个时间点阻塞进程。只有最后一种**异步I/O**才是真正的异步。目前，**I/O多路复用**是Linux系统下实现高并发网络应用最主流、最高效的模型。

---

### I/O 多路复用三种实现机制

#### **select、poll、epoll**

`select`、`poll`和 `epoll`都是 Linux 下实现 I/O 多路复用的核心机制，但它们的设计和性能有着代际般的差异。

**首先是最基础的 `select`。** 它的工作方式是轮询，每次调用都需要将整个需要监听的文件描述符集合从用户态拷贝到内核态，然后由内核线性扫描所有描述符来判断是否就绪。它的主要问题是性能会随着连接数的增加而线性下降，并且有 1024 这个连接数的硬性限制。

**然后是 `poll`。** 它改进了 `select`的一些缺陷，用动态的 pollfd 结构数组替代了固定的位图，从而解除了连接数的限制。但它的本质依然是轮询，内核依然需要线性扫描所有被监视的描述符，所以性能瓶颈依然存在。

**最后是现代高性能的 `epoll`。** 它完全采用了事件驱动的设计。我们通过 `epoll_ctl`预先将描述符注册到内核，内核会通过回调机制来管理事件就绪的通知。当调用 `epoll_wait`时，它只是从内核的一个就绪事件链表中取出结果并返回，而无需遍历整个集合。这使得它的性能不会随着连接数的增加而下降，只与活跃连接的数量正相关，因此能够轻松应对数万甚至数十万的并发连接。

**总结来说，三者的演进路径是从低效的轮询（select/poll）走向了高效的事件通知（epoll）。** `select`和 `poll`适用于跨平台或连接数极少的场景，而 `epoll`则是 Linux 下构建高性能网络服务的绝对首选和基石，像 Nginx 和 Redis 都深度依赖它。

#### epoll 的 边缘触发和水平触发有什么区别

“`epoll`的**边缘触发**和**水平触发**是两种非常重要的事件通知模式，它们的区别核心在于**内核通知应用程序文件描述符就绪的时机和条件**。

**1. 水平触发**

- **工作方式**：只要文件描述符对应的读或写缓冲区**处于**“非空”或“非满”的状态（即可读或可写），`epoll`就会持续通知应用程序。
- **行为类比**：这就像把一个开关**按住**不放，只要条件满足，灯就会一直亮着。
- **影响**：在这种模式下，应用程序在收到一次可读通知后，**即使没有一次性读完所有数据**，下次调用 `epoll_wait`时，`epoll`会再次通知这个描述符可读，直到缓冲区被读空。写入同理。
- **优点**：对程序员更友好，不容易遗漏事件，编码更简单。
- **缺点**：可能会导致不必要的重复通知，如果应用程序不想处理，需要自己记录状态。

**2. 边缘触发**

- **工作方式**：只有当文件描述符对应的缓冲区状态**发生变化时**（例如从不可读变为可读，或从不可写变为可写），`epoll`才会通知一次应用程序。
- **行为类比**：这就像是一个开关的**上升沿**，只有在**按下开关的瞬间**灯会亮一下，之后无论你按着不放还是松开，它都不会再持续亮着。
- **影响**：在这种模式下，应用程序在收到一次可读通知后，**必须一次性将缓冲区内的数据全部读完**，直到产生 `EAGAIN`或 `EWOULDBLOCK`错误为止。因为即使缓冲区里还有数据，只要没有**新的数据到来**（即状态没有再次发生变化），`epoll`就**不会再通知**。
- **优点**：减少了重复通知，性能更高，尤其适合需要精细控制I/O行为的场景。
- **缺点**：编程复杂度高，应用程序必须一次处理完所有数据，否则会丢失事件。通常需要搭配**非阻塞I/O**来循环读/写，直到出现 `EAGAIN`。

### 其他

{% folding child:codeblock open:false color:red 服务器处理并发请求有哪几种方式？ %}

服务器处理并发请求的核心目标是**高效地利用硬件资源（CPU、内存）来同时服务大量客户端**。其主流方式主要分为三大类，它们体现了不同的设计哲学和演进过程：

**第一类：多进程模型**

这是最传统的方式。主进程（监听者）接受新连接，然后**fork**出一个新的子进程来专门处理这个连接的后续请求。

- **优点**：
  - **稳定性高**：进程间地址空间完全隔离，一个进程的崩溃不会影响其他进程。
- **缺点**：
  - **资源开销大**：创建进程、进程间上下文切换以及独立内存空间的成本很高。
  - **进程间通信复杂**：数据共享需要通过IPC（管道、共享内存等）机制，比较复杂。
- **典型代表**：早期Apache服务器的`prefork`模式。

**第二类：多线程模型**

这是对多进程模型的优化。主线程接受连接，然后创建新的工作线程来处理连接，所有线程共享进程的地址空间和资源。

- **优点**：
  - **资源开销较小**：创建线程和线程间上下文切换的开销远小于进程。
  - **数据共享简单**：线程间共享全局变量和内存，通信非常方便。
- **缺点**：
  - **编程复杂**：需要严格的同步机制（锁、信号量）来保护共享数据，否则会导致数据竞争和死锁等问题，对开发者要求高。
  - **稳定性风险**：一个线程的严重错误（如内存越界）可能导致整个进程崩溃，牵连所有其他线程。
- **典型代表**：Apache服务器的`worker`模式、Java Tomcat的默认模式。

**第三类：I/O多路复用 + 事件驱动模型**

这是现代高性能服务器（如Nginx、Redis、Node.js）采用的架构。其核心是**单线程（或少量线程）通过I/O多路复用技术（如epoll、kqueue）来同时监控和管理成千上万个连接**。

- **工作流程**：一个线程循环调用`epoll_wait()`，当监听到某些连接上有事件（如可读、可写）发生时，就去处理这些事件。整个过程是**非阻塞**和**异步**的。
- **优点**：
  - **极高的资源效率**：用极少的线程（通常CPU核数）即可处理海量连接，极大地减少了内存和上下文切换的开销。
  - **高性能**：非常适合I/O密集型应用（如网络代理、聊天服务），能够轻松应对C10K甚至C100K问题。
- **缺点**：
  - **编程模型复杂**：异步回调的风格打破了传统的线性思维，代码调试和维护难度较高。
  - **CPU密集型任务处理不佳**：如果一个事件处理耗时很长，会阻塞整个事件循环，影响其他所有连接的反应速度。通常需要通过结合多进程（如Nginx）来将计算任务分摊到多个worker进程来解决。
- **典型代表**：Nginx, Redis, Node.js。

**总结**

目前，最主流的现代高性能服务器架构是 **“I/O多路复用 + 多线程/进程池”** 的混合模式：

- 使用**I/O多路复用**来处理海量连接的I/O事件，发挥其高并发的优势。
- 使用**一个预先创建好的线程池/进程池**来处理计算密集型任务，避免事件循环被阻塞。

这种架构在资源效率、性能和编程复杂性之间取得了最佳平衡。

{% endfolding %}



{% folding child:codeblock open:false color:red redis，nginx，netty 是依赖什么做的这么高性能？ %}

Redis、Nginx 和 Netty 虽然属于不同领域的软件，但它们能达到极高的性能，主要依赖于一套共通的、经过验证的高性能架构模式和技术选型。我可以将它们依赖的核心技术总结为以下四个层面：

**第一，也是最核心的：它们都采用了 I/O 多路复用模型，而且是 Linux 平台下性能最高的 `epoll`。**

传统的多线程/多进程模型为每个连接创建一个线程，上下文切换和内存开销巨大。而它们使用**单个或少量线程**（Nginx 的 Worker 进程，Redis 的主线程，Netty 的 Boss/Worker 事件循环组）通过 `epoll`就能管理**数万个连接**。这极大地降低了资源消耗，将 CPU 从繁重的线程调度中解放出来，专注于处理真正的 I/O 事件。

**第二，它们都遵循了事件驱动的 Reactor 模式。**

这个模式与 I/O 多路复用是完美搭档。整个系统是一个**事件循环**，核心工作流程是：`收集事件（epoll_wait）-> 分发事件 -> 处理事件`。这种异步、非阻塞的处理方式避免了线程的等待和阻塞，让有限的线程资源得到最大程度的利用，实现了高吞吐量。

**第三，在内存和数据处理上，它们都追求极致的效率。**

- **Redis**：1. 将数据完全存储在内存中，避免了磁盘 I/O 的瓶颈。2. 使用了精心设计的自定义数据结构（如 SDS、跳跃表、压缩列表），在时间和空间上做了极致的优化。
- **Nginx**：1. 采用了高效的内存池管理，减少频繁的内存分配和释放带来的开销和碎片。2. 设计了零拷贝技术，在发送文件数据时，数据无需从内核空间拷贝到用户空间，直接在内核中完成传输，极大提升了静态文件服务的性能。
- **Netty**：1. 提供了零拷贝的 `ByteBuf`机制，减少了数据在 JVM 堆内存和本地内存之间的拷贝。2. 使用对象池和内存池化技术，避免频繁创建和销毁对象，减轻 GC 压力。

**第四，采用单线程或特定多线程模型，避免锁竞争。**

- **Redis**：其网络 I/O 和数据操作的核心模块是**单线程**的。这虽然无法利用多核，但完美避免了多线程环境下复杂的锁竞争和上下文切换问题，保证了原子性和极高的执行效率。对于耗时的操作（持久化），会 fork 出子进程去执行。
- **Nginx**：采用**多进程 + 单线程**模型。多个 Worker 进程是平等的，各自独立运行一个事件循环，充分利用多核CPU，且进程间相互隔离，稳定性极高。
- **Netty**：采用**主从 Reactor 多线程**模型。Boss 线程组负责接收连接，Worker 线程组负责处理 I/O。通过精心设计，将连接合理地分配到不同的 Worker，确保了每个事件循环中所处理的连接是独立的，极大地减少了并发冲突。

**总结一下，** 它们高性能的共性在于：**基于 `epoll`的事件驱动架构 + 非阻塞 I/O + 极致的资源管理（内存、CPU）+ 避免锁竞争的精巧并发模型**。这套技术栈是现代高性能网络服务的标准答案。

{% endfolding %}



## 其他重要概念

### 内核

内核是操作系统最核心、最基础的部分，它是操作系统的核心。它的核心职责是作为应用程序和计算机硬件之间的桥梁，管理所有系统资源，并为上层应用提供一个安全、稳定、统一的运行环境。

它的主要工作可以概括为以下四个核心方面：

第一，是**进程管理**。创建、调度和终止进程与线程。它通过CPU调度算法，决定下一个获得CPU计算资源的进程是谁。

第二，是**内存管理**。内核为每个进程分配独立的虚拟内存空间，并通过页表等机制将虚拟地址映射到物理内存上

第三，是**设备驱动与硬件抽象**。通过设备驱动程序来管理所有硬件设备。向上层应用提供了一个简单统一的接口来使用硬件。

第四，是**文件系统管理**。管理存储在磁盘上的数据，并处理文件的创建、读写、删除以及权限控制等所有操作。

为了实现这些功能，内核运行在CPU最高权限的“内核态”，可以直接操作硬件。而我们普通的应用程序则运行在受限的“用户态”，无法直接访问硬件。当应用程序需要执行特权操作（比如读写文件、申请内存）时，必须通过“系统调用”来请求内核代为完成。

这种设计的最大好处是**安全性和稳定性**。即使某个应用程序崩溃，它也不会直接破坏硬件或其他程序，因为所有关键操作都由内核这个可靠的中介来统一管理和仲裁。

### 内核态和用户态

内核态和用户态是操作系统中的两种运行模式。是CPU的运行状态。

#### 区别

内核态：CPU可以执行所有的指令和访问所有的硬件资源，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。主要用于操作系统内核的运行。

用户态：用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态去完成。主要用于运行用户程序。

#### 为什么要划分为内核态和用户态

1，通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。

2，当用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃。

3，这种划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。

#### 用户态切换到内核态的方式(场景/起因)

用户态切换到内核态的方式有三种：

1，**系统调用**：指用户态主动要求切换到内核态执行某些需要特殊权限的操作，最常用、最主动的方式。

2，**异常**：当CPU在执行用户态程序时，发生了不可预知的**异常**（如除零错误、缺页异常、非法指令），CPU会自动停止当前工作，转而去执行内核中对应的异常处理程序。

3，**中断**：由硬件发起(如键盘输入、网卡收到数据、磁盘IO完成)，CPU会立即暂停当前执行流程，转而去执行内核中对应的中断处理程序。

#### 用户态和内核态如何切换(机制/过程)

当用户态需要切换到内核态时，会触发一个称为 **“陷入”** 的机制：

当触发系统调用/异常/中断，CPU会把当前用户进程的信息保存到这个进程的**内核栈**，然后将自己的工作模式从用户态提升至内核态，然后根据预先由操作系统设置好的**中断向量表**，查找并确定该由哪个内核中的服务程序来处理当前事件，然后执行这个服务程序真正操作硬件或管理资源。内核程序执行完毕后，会执行一条**中断返回指令**。这条指令会触发CPU将之前保存的现场信息从内核栈中恢复出来，并将CPU的工作模式从**内核态**切换回**用户态**，然后继续执行原来的用户进程。

### 内核空间和用户空间

在计算机系统中，内存可以分为两大区域：内核空间（Kernel Space）和用户空间（User Space）。这种划分主要用于保护系统稳定性和安全性。

**内核空间**，是操作系统内核代码及其运行时数据结构所在的内存区域，拥有对系统所有资源的完全访问权限。

**⽤户空间**，是操作系统为应用程序（如用户运行的进程）分配的内存区域，用户空间中的进程不能直接访问硬件或内核数据结构，只能通过系统调用与内核通信。

### PCB

**PCB（Process Control Block）** 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB，用于记录该进程的全部关键信息。

**PCB 通常包含以下内容：**

1. **进程标识信息**：如进程 ID（PID）、父进程 ID；
2. **处理器状态信息**：保存 CPU 寄存器、程序计数器（PC）、程序状态字（PSW）等，用于进程切换时恢复上下文；
3. **进程控制信息**：如进程状态（就绪、运行、阻塞等）、优先级、调度信息；
4. **内存管理信息**：如页表、段表、内存分配情况；
5. **文件管理信息**：打开的文件列表、I/O 资源信息；
6. **通信信息**：用于进程间通信的缓冲区、消息队列、信号等信息。



































