---
title : MQ
order : 6
---

# 消息队列

消息队列是一种异步的进程间通信方式，主要用于解决分布式系统中的组件通信问题。它的核心模型是 **‘生产者/消费者’模型**：生产者发送消息到队列，消费者从队列中获取消息进行处理。双方不需要同时在线，也不需要知道彼此的存在。

## 作用

1. **系统解耦**：这是它最重要的作用。假设系统A需要调用系统B的接口。如果不使用消息队列，系统A和系统B是**强耦合**的，如果系统B宕机或接口变更，系统A会立刻受到影响。引入了消息队列后，系统A只需要把消息发送出去就算完成任务，完全不需要关心谁来处理、何时处理。系统B也只需要从队列里取消息，而不需要关心消息的来源。这样，两个系统就通过一个中间件**解耦**了，彼此的依赖性和影响降到了最低。
2. **异步处理**：对于一些非核心的、耗时的操作（比如下单成功后发短信、发优惠券），主流程不需要等待它们完成，只需要发一个消息到队列就可以直接返回，极大地缩短了响应时间，提升了用户体验。
3. **削峰**：在流量高峰时期（比如秒杀），大量的请求瞬间涌入，后端服务可能无法承受。消息队列可以作为一个**缓冲区**，将这些请求平稳地接收下来，后端服务可以按照自己能处理的速度慢慢消费，避免了系统被突发流量冲垮。

---

除此之外，还有：

**1. 实现最终一致性（分布式事务）**

这是消息队列在微服务架构中一个核心且经典的应用。它通过**事务消息**或**本地事务表**等模式，来解决分布式系统下的数据一致性问题。

- **场景**：用户下单支付成功后，需要更新订单状态、扣减库存、增加积分。这三个操作分属不同服务，必须保证同时成功或失败。
- **如何做**：订单服务在本地数据库事务中，更新订单状态并**向消息队列发送一条事务消息**。消息队列保证这条消息最终一定能被投递。库存和积分服务消费这条消息，执行各自操作。通过**重试机制**，确保这些操作最终都会成功，从而实现所有系统数据的**最终一致性**。**RocketMQ** 提供了完整的事务消息方案。

**2. 顺序保证**

在某些业务场景下，消息必须严格按照产生的顺序被处理。

- **场景**：一个账户的“创建账户” -> “存入100元” -> “取出50元” 这三个操作必须按顺序执行，乱序会导致账户余额错误。
- **如何做**：在 **Kafka** 或 **RocketMQ** 中，通过将需要保证顺序的消息发送到同一个 **Topic 的同一个 Partition** 中。因为一个分区只能被一个消费者顺序消费，从而天然保证了消息的顺序性。

**3.数据流处理（流平台）**

这是将消息队列能力发挥到极致的场景。此时它不再仅仅是“消息中间件”，而是一个**实时的数据流平台**，是大数据领域的基石。

- **场景**：实时用户行为分析、实时监控告警、实时推荐系统。
- **如何做**：各种应用（如前端、后端服务）作为生产者，将日志、点击事件、监控指标等数据以流的形式持续写入 **Kafka**。下游的流处理框架（如 **Flink、Spark Streaming**）实时消费这些数据流，进行清洗、聚合、计算。结果可用于实时大屏或驱动业务逻辑。Kafka 的高吞吐和持久化特性使其成为**事实上的流数据标准源**。

**4. 延时/定时调度**

消息队列可以作为一个分布式的、高可用的定时器。

- **场景**：订单下单后30分钟未支付自动关闭；预约会议开始前15分钟发送提醒。
- **如何做**：**RocketMQ** 原生支持延迟消息，可在发送时指定延迟级别。**RabbitMQ** 可通过 `TTL`（消息存活时间）和 `死信队列`机制来实现。消息会在队列中等待指定时间后才被投递给消费者。

**5. 系统重构与数据同步**

在系统重构或数据迁移期间，消息队列是保证业务平滑过渡和数据一致性的利器。

- **场景**：将单体数据库拆分为多个微服务数据库，需要实时同步用户数据。
- **如何做**：旧系统在修改数据时，同时向消息队列发送一条数据变更消息。新系统订阅这些消息，从而在自己的数据库中维护一份相同的用户数据。这种方式对原有系统侵入性小，实现了数据的实时同步。

---

## 可能带来哪些问题

**系统可用性降低：** 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！

**系统复杂性提高：** 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！

**一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了

---

## 如何保证幂等写

幂等性是指 同一操作的多次执行对系统状态的影响与一次执行结果一致。例如，支付接口若因网络重试被多次调用，最终应确保仅扣款一次。实现幂等写的核心方案：

- 唯一标识（幂等键）：客户端为每个请求生成全局唯一ID（如 UUID、业务主键），服务端校验该ID是否已处理，适用场景接口调用、消息消费等。
- 数据库事务 + 乐观锁：通过版本号或状态字段控制并发更新，确保多次更新等同于单次操作，适用场景数据库记录更新（如余额扣减、订单状态变更）。
- 数据库唯一约束：利用数据库唯一索引防止重复数据写入，适用场景数据插入场景（如订单创建）。
- 分布式锁：通过锁机制保证同一时刻仅有一个请求执行关键操作，适用场景高并发下的资源抢夺（如秒杀）。
- 消息去重：消息队列生产者为每条消息生成唯一的消息 ID，消费者在处理消息前，先检查该消息 ID 是否已经处理过，如果已经处理过则丢弃该消息。

---

## JMS 和 AMQP

- **JMS**：是一个 **Java 平台的 API 规范/标准**，它定义了如何编写Java代码来和消息中间件进行交互。它关心的是**接口**。
- **AMQP**：是一个**跨语言的**、**线级的** **网络协议**。它定义了数据在网络上的传输格式。它关心的是**通信**。

---

JMS 是 Java EE 的一部分，它只是一套接口，本身并不实现消息的收发。它的主要目的是，让 Java 开发者能够用一套统一的API来操作不同的消息中间件，从而实现**解耦**。

**JMS 两种消息模型**：

- **点对点模型**：消息发送到**队列**。一个消息只能被**一个消费者**消费。
- **发布/订阅模型**：消息发送到**主题**。一个消息会被**所有订阅了该主题的消费者**消费。

---

它的核心是更灵活的**路由机制**：

- **生产者**将消息发送到 **Exchange**（交换机），并指定一个 **Routing Key**。
- **Exchange** 根据自身的**类型**和与 **Queue** 的 **Binding** 规则，将消息路由到一个或多个队列中。
- **消费者**从 **Queue** 中获取消息。

---

**AMQP提供了五种消息模型**：①direct exchange；②fanout exchange；③topic change；④headers exchange；⑤system exchange。本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分；

---

**二者区别:**

AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。

JMS 支持 `TextMessage`、`MapMessage` 等复杂的消息类型；而 AMQP 仅支持 `byte[]` 消息类型（复杂的类型可序列化后发送）。

由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。

---

## RPC vs 消息队列

- **从用途来看**：RPC 主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。消息队列主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰。
- **从通信方式来看**：RPC 是双向直接网络通讯，消息队列是单向引入中间载体的网络通讯。
- **从架构上来看**：消息队列需要把消息存储起来，RPC 则没有这个要求，因为前面也说了 RPC 是双向直接网络通讯。
- **从请求处理的时效性来看**：通过 RPC 发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理。

RPC 和消息队列本质上是网络通讯的两种不同的实现机制，两者的用途不同，万不可将两者混为一谈。

---

## 常见的消息队列

**1. Apache Kafka**

- **定位**：**分布式流处理平台**，主打高吞吐、高扩展性。
- **特点**：
  - **极致性能**：采用顺序写、页缓存、零拷贝等技术，吞吐量可达百万级/秒，在大数据领域是事实标准。
  - **持久化**：消息会持久化到磁盘，并支持多副本，数据可靠性高。
  - **生态丰富**：与 Flink、Spark、Storm 等流处理框架无缝集成。
- **典型场景**：**日志收集**、**用户行为跟踪**、**流式数据处理**、**Metrics 监控数据**等海量数据且允许少量延迟的场景。

**2. RabbitMQ**

- **定位**：**传统企业级消息代理**，主打可靠性、灵活的路由和强大的管理界面。
- **特点**：
  - **协议支持**：率先支持 **AMQP** 协议，提供了灵活的消息路由机制（Exchange、Binding）。
  - **功能丰富**：支持消息确认、持久化、死信队列、优先级队列等企业级特性。
  - **管理友好**：提供非常完善和友好的 Web 管理界面。
- **典型场景**：**业务系统解耦**、**异步任务处理**、**订单系统**等对消息可靠性要求高、业务逻辑复杂的场景。

**3. Apache RocketMQ**

- **定位**：**金融级可靠**的消息队列，是阿里开源的产品，在国内非常流行。
- **特点**：
  - **金融级数据一致性**：提供完整的**事务消息**解决方案，是其在电商、金融等领域的核心优势。
  - **海量消息堆积**：支持万亿级消息堆积能力，处理慢消费场景能力强。
  - **功能全面**：同时支持顺序消息、延迟消息、轨迹消息等。
- **典型场景**：**电商交易**、**金融支付**等对事务一致性要求极高的核心业务系统。

**4. Apache Pulsar**

- **定位**：新一代**云原生**消息流平台，被誉为 Kafka 的有力竞争者。
- **特点**：
  - **存算分离架构**：采用计算（Broker）和存储（BookKeeper）分离的架构，使其扩展性极佳，故障恢复更快。
  - **多租户支持**：原生支持多租户，非常适合云上部署和大公司内部平台化。
  - **一体化**：同时支持队列和流两种语义，社区活跃。
- **典型场景**：**云原生环境**、**多租户SaaS平台**、**需要极致弹性的消息平台**。

**5. Redis**

- **定位**：**内存型**数据结构存储，但其 Pub/Sub 和 List 结构可用于简单的消息队列场景。
- **特点**：
  - **极致快**：基于内存操作，延迟极低。
  - **功能简单**：没有持久化（Pub/Sub）、没有ack机制、无高级特性，消息容易丢失。
- **典型场景**：**简单的发布订阅**（如聊天室、服务发现）、**实时性要求极高但允许消息丢失**的业务。

---

## 消息队列选型

1. **如果是需要处理海量日志、用户行为数据的场景**，我会选择 **Kafka**，因为它的**吞吐量是最大的，天生为大数据管道而生**。
2. **如果是电商、支付等对事务一致性要求极高的核心业务场景**，我会选择 **RocketMQ**，因为它**提供了完整的金融级事务消息解决方案**。
3. **如果是业务系统解耦、需要灵活路由规则的场景**，我会选择 **RabbitMQ**，因为它的**Exchange模型提供了最强大的消息路由能力**。
4. **如果是需要极低延迟的实时通信场景**，我会选择 **RabbitMQ**，因为它的**消息推模式能带来毫秒甚至微秒级的延迟**。
5. **如果是云原生环境，需要极致弹性和隔离性的场景**，我会考虑 **Pulsar**，因为它的**存算分离架构更适合云原生部署和多租户隔离**。
6. **如果是一个简单的项目，需要快速上手和友好运维的场景**，我会选择 **RabbitMQ**，因为它**拥有开箱即用的强大管理界面**。

---

## 重复消费、消息丢失、可靠性、顺序性、消息积压、数据一致性



---

## 其他

### 消息队列参考哪种设计模式

**1. 观察者模式 / 发布-订阅模式**

这是消息队列最直接、最核心的参考模式。

- **模式核心**：定义了一种**一对多**的依赖关系，当一个对象（主题）的状态发生改变时，所有依赖于它的对象（观察者）都会得到通知并自动更新。
- **在消息队列中的体现**：
  - **主题 (Subject)** -> **Topic** (主题) 或 **Exchange** (交换机)
  - **观察者 (Observer)** -> **Consumer** (消费者)
  - **状态改变/通知** -> **Message** (消息)
- **工作方式**：**生产者**（发布者）将消息发布到一个**主题**，多个**消费者**（订阅者）订阅该主题，并在消息到达时自动接收并处理。
- **价值**：实现了**彻底的解耦**。生产者完全不知道也不关心有多少个消费者、它们是谁、以及它们如何处理消息。它只负责发布消息。

**2. 代理模式**

消息队列本身在整个架构中就扮演着一个“代理”的角色。

- **模式核心**：为其他对象提供一种代理，以控制对这个对象的访问。代理站在客户端和目标对象之间，起到中介和保护的作用。
- **在消息队列中的体现**：
  - **代理 (Proxy)** -> **Message Broker** (消息代理，即RabbitMQ/Kafka/RocketMQ服务器本身)
  - **目标对象 (Real Subject)** -> 真正的**消费者服务**
- **工作方式**：生产者不直接调用消费者服务，而是把请求（消息）发送给**消息代理**。由代理来负责消息的路由、持久化、可靠投递等一系列复杂操作，最终再将消息分发给消费者。这保护了消费者，使其不会被生产者的突发流量冲垮。
- **价值**：实现了**异步处理**和**流量削峰**。代理作为一个缓冲区，平衡了生产者和消费者之间的速度差异。

---

### 如何设计一个消息队列@



---

# Kafka

## 基础

Kafka本质上是一个**分布式的、高吞吐量的、基于发布订阅模式的流处理平台**，而不仅仅是一个传统的消息队列。它的设计目标就是处理海量的实时数据流。

---

### **特点**

**1. 高吞吐量与低延迟**

这是Kafka最广为人知的特点。它能在普通的硬件上支持每秒数十万甚至百万级的消息吞吐，同时保持毫秒级的延迟。这主要得益于其三大核心技术：

- **顺序读写磁盘**：Kafka将消息持续追加到日志文件末尾，充分利用了磁盘顺序读写速度远快于随机读写的特性。
- **零拷贝技术**：消费者读取数据时，数据直接从磁盘文件通过DMA方式传输到网卡， bypass了应用程序和CPU的多次拷贝，极大减少了开销。
- **页缓存与批量处理**：大量利用操作系统页缓存，减少了JVM GC压力；同时生产者和消费者都支持批量操作，大幅提升了网络和I/O效率。

**2. 可持久化与高可靠**

Kafka不像某些内存队列，它**将所有消息持久化到磁盘**，并且支持配置多副本机制。每个分区的数据都有多个副本，分布在不同Broker上，一旦主副本宕机，其他副本会迅速接管，保证了数据的可靠性和服务的可用性，消息不会丢失。

**3. 高可扩展性**

Kafka的扩展性极佳，体现在：

- **水平扩展**：集群可以通过简单地增加Broker来提升整体性能。Topic可以划分为多个**Partition**，这些Partition可以分布在不同Broker上，实现了数据的分布式存储和并行处理。
- **松耦合**：生产者和消费者与集群是解耦的，客户端的增减不会影响Broker集群。

**4. 丰富的生态系统**

Kafka不仅仅是一个消息队列，更是一个完整的**流处理平台**。其强大的**Kafka Connect**和**Kafka Streams**组件，使得它能够轻松地与各种数据源集成并实现复杂的流式数据处理，成为了大数据领域事实上的标准数据管道。

---

### 为什么快

顺序写入优化：Kafka将消息顺序写入磁盘，减少了磁盘的寻道时间。这种方式比随机写入更高效，因为磁盘读写头在顺序写入时只需移动一次。

批量处理技术：Kafka支持批量发送消息，这意味着生产者在发送消息时可以等待直到有足够的数据积累到一定量，然后再发送。这种方法减少了网络开销和磁盘I/O操作的次数，从而提高了吞吐量。

零拷贝技术：Kafka使用零拷贝技术，可以直接将数据从磁盘发送到网络套接字，避免了在用户空间和内核空间之间的多次数据拷贝。这大幅降低了CPU和内存的负载，提高了数据传输效率。

压缩技术：Kafka支持对消息进行压缩，这不仅减少了网络传输的数据量，还提高了整体的吞吐量。

---

### **核心概念**

Kafka的核心架构围绕几个关键概念构建：

- **Producer & Consumer**：生产者和消费者，分别是数据的发送方和接收方。
- **Broker**：Kafka集群由多个服务器节点组成，每个节点就是一个Broker，负责接收、存储和投递消息。
- **Topic**：数据流的类别或主题，生产者向Topic发送消息，消费者订阅Topic消费消息。
- **Partition**：这是Kafka实现高并发和水平扩展的**核心设计**。每个Topic可以被分成多个Partition，分布在不同Broker上。消息以**追加**的形式写入Partition，保证了顺序性。
- **Consumer Group**：这是实现“发布-订阅”模式的关键。同一个Consumer Group内的多个消费者共同消费一个Topic，每条消息只会被组内的一个消费者消费，从而实现负载均衡。

---

### **应用场景**

Kafka主要用在两大类场景：

1. **消息系统**：作为企业级的消息总线，进行系统解耦和异步通信。
2. **流处理平台**：这是它更核心的定位。常用于**实时日志收集**、**用户行为跟踪**、**运营指标监控**等，作为大数据流处理管道（与Flink、Spark Streaming集成）的**数据源**。

---

### 相比于其他消息队列的优势

主要的优势如下：

1. **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

------

### 消息模型

**Kafka 的消息模型是基于发布-订阅模式的，其核心实现依赖于三个关键概念：主题（Topic）、分区（Partition）和消费者组（Consumer Group）。**

1. **生产者（Producer）将消息发布到特定的主题（Topic）**。主题是消息的类别或 feed 名称。
2. **每个主题可以被划分为多个分区（Partition）**。分区是 Kafka 实现水平扩展和并行处理的基础。
   - 消息在分区内以**有序的、不可变序列**方式存储，每条消息都有一个唯一的偏移量（Offset）。
   - 生产者将消息发送到主题时，Kafka 会根据消息的 Key（或轮询策略）决定将其写入哪个分区。
3. **消费者通过消费者组（Consumer Group）进行订阅和消费**。
   - 一个消费者组可以包含多个消费者实例。
   - **组内的所有消费者协同工作，共同消费一个主题的所有消息**。每个分区在同一时间只能被组内的**一个消费者**消费。
   - 这种设计实现了“负载均衡”和“扇出”两种模式：
     - **负载均衡（竞争消费者模式）**：所有消息被均衡地分配给组内的消费者实例处理。
     - **扇出（发布-订阅模式）**：同一个主题可以被**多个不同的消费者组**订阅，每个组都会收到全部消息的副本。

**总结来说，Kafka 的消息模型是通过“主题-分区-消费者组”的机制，将消息流进行分割（分区）并由多个消费者（组）并行处理，从而实现了高吞吐量和可扩展性。**

------

## 机制

### 多副本机制

“Kafka的多副本机制是它保证数据不丢和服务高可用的核心设计。我了解它的核心思想是为同一份数据创建多个备份。

**1. 它是怎么工作的？**

- 对于每个数据分片（Partition），Kafka都会创建多个副本，存放在不同的服务器上。
- 这些副本里，只有一个“老大”，叫做 **Leader**，负责处理所有的读写请求。
- 其他副本都是“小弟”，叫做 **Follower**。它们只做一件事：不停地从Leader那里拷贝数据，努力保持和Leader的数据一致。

**2. 它带来了两大核心好处：**

- **第一，高可用，服务不停机。** 这是最重要的好处。如果存放Leader的那台服务器宕机了，Kafka会立刻从那些数据同步得好的Follower里，自动选出一个新的Leader来顶替。这个切换过程非常快，用户几乎感觉不到，这样就保证了服务一直在线。
- **第二，高可靠，数据不丢失。** 因为同一份数据有好几个备份，即使坏掉一两台机器，数据依然安全地保存在其他机器的副本上，这样就保证了消息不会丢失。

**3. 一个关键概念：ISR（同步副本集合）**

- 不是所有Follower都能随时被选为Leader。只有那些和Leader数据差得不多的、处于“同步中”的Follower，才会被放在一个叫 **ISR** 的名单里。
- 一旦Leader宕机，只有在这个ISR名单里的Follower才有资格参加新Leader的选举。这样可以确保新Leader上的数据是最全的，避免数据错乱。

**总结一下：** Kafka通过让多个副本‘一主多从’分工协作的方式，用额外的机器和存储空间作为代价，换来了系统极高的可靠性和可用性。”

------

### 重试机制

在消费过程中，当其中一个消息消费异常时，会进行重试，重试多次后会跳过当前消息，继续进行后续消息的消费，不会一直卡在当前消息。

默认配置下，会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败。

---

**自定义重试次数以及时间间隔**，只需要在 `DefaultErrorHandler` 初始化的时候传入自定义的 `FixedBackOff` 即可。重新实现一个 `KafkaListenerContainerFactory` ，调用 `setCommonErrorHandler` 设置新的自定义的错误处理器就可以实现。

------

**自定义重试失败后逻辑**，需要手动实现，重写 `DefaultErrorHandler` 的 `handleRemaining` 函数，加上自定义的告警等操作。`DefaultErrorHandler` 只是默认的一个错误处理器，Spring Kafka 还提供了 `CommonErrorHandler` 接口。手动实现 `CommonErrorHandler` 就可以实现更多的自定义操作，有很高的灵活性。例如根据不同的错误类型，实现不同的重试逻辑以及业务逻辑等

---

**重试失败的数据怎么处理**

**死信队列（Dead Letter Queue，简称 DLQ）** 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被"丢弃"或"死亡"的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。

---

## Zookeeper

**ZooKeeper 是一个开源的分布式协调服务**。它就像一个**分布式系统的“大脑”或“总控中心”**，为大型分布式应用提供**统一配置管理、分布式锁、领导者选举**和**服务注册与发现**等核心协同功能，保证集群中各个节点间的状态一致性与可靠协同。

它的数据模型类似于**文件目录树**，通过其提供的原语，开发人员可以轻松构建高可用的分布式应用。**Kafka、Hadoop、HBase** 等众多知名分布式系统都依赖它来实现协调管理。

---

在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构。

---

**作用**

ZooKeeper在早期的Kafka架构中，扮演着**‘分布式协调员’** 的核心角色，主要负责维护和管理整个Kafka集群的**元数据**和**状态信息**。它的作用主要体现在以下四个方面：

1. **Broker管理：服务的注册与发现**
   - Kafka的每个Broker（服务器）启动时，都会到ZooKeeper上的一个指定目录（如`/brokers/ids`）里**注册**一个临时节点，把自己的地址、端口等信息写上去。
   - 这样，所有Broker和客户端（Producer、Consumer）都能从ZooKeeper上**实时感知到**当前有哪些Broker是存活在线的。这是实现服务发现的基础。
2. **Topic与Partition的元数据管理**
   - 所有Topic的配置信息、它们被分成了几个Partition、每个Partition的副本存放在哪些Broker上……这些重要的**元数据**都存储在ZooKeeper中。
   - 客户端需要知道去哪个Broker上找到某个Topic的某个Partition，就需要先查询ZooKeeper。
3. **Controller的选举与脑裂避免**
   - 这是ZooKeeper**最关键的作用**。Kafka集群中需要有一个**唯一的领导者**，叫做Controller。
   - Controller负责管理分区和副本的状态，比如监控Broker故障并触发**Leader副本的重新选举**。
   - 所有Broker都会尝试在ZooKeeper上抢占创建一个**临时节点**（比如`/controller`）。ZooKeeper能保证最终**只有一个Broker能创建成功**，这个Broker就成为Controller。这样就完美避免了“脑裂”（出现多个领导者）的问题。
4. **消费者组的位移管理（老版本）**
   - 在比较老的Kafka版本中，Consumer消费到了哪个位置（Offset）这个信息也是提交到ZooKeeper来保存的。
   - **但需要特别说明的是**，新版本的Kafka已经将消费位移的管理迁移到了Kafka内部一个叫做`__consumer_offsets`的特殊Topic中，不再依赖ZooKeeper，以此来提升性能和降低依赖。

**总结来说，ZooKeeper就像是Kafka集群的‘大脑’和‘信息公告板’，它不参与实际的数据传输，但负责维护集群里‘谁活着、谁是什么角色、数据在哪’这些最重要的元信息，保证了整个集群的协调一致和高可用。**

------

## 消费顺序、消息丢失、重复消费、消息积压、高可用

### 如何保证消费顺序

Kafka保证消息消费顺序的方式非常巧妙，它**只在分区级别保证严格的消息顺序**，而不是在主题级别。

**1. 核心机制：分区内的顺序性**

- Kafka的每个**分区（Partition）** 都是一个有序的、不可变的消息序列。
- 消息在写入分区时会获得一个唯一的**偏移量（Offset）**，这个偏移量就是它在分区中的顺序标识。
- 消费者实例在消费某个分区时，会按偏移量的顺序依次读取消息。这就保证了**在单个分区内，消息的消费顺序与生产顺序是完全一致的**。

**2. 如何利用这一机制？**

如果业务上需要保证一组消息的顺序，我们必须确保这些消息都被发送到**同一个分区**。实现这一点最常见的方法是：

- 在发送消息时，为消息指定一个**Key**。
- Kafka的生产者客户端会根据这个Key的哈希值，计算出它应该被路由到哪个分区。
- 因此，**所有具有相同Key的消息，都会被发送到同一个分区**，从而保证了这些消息的顺序性。

**举例说明：**

假设要保证同一个订单的所有状态变更消息（创建订单 -> 付款 -> 发货 -> 完成）必须按顺序消费。我们可以在生产消息时，**使用订单ID作为Key**。这样，所有关于这个订单的消息都会进入同一个分区，并被消费者按顺序处理。

**3. 重要的限制与权衡**

- **全局顺序**：如果需要保证整个Topic的全局顺序，只能将Topic设置为仅有**1个分区**。但这会严重限制Topic的吞吐量和并发能力，通常不建议这样做。
- **消费者并发**：要消费一个分区，一个消费者组内最多只能有一个消费者实例。如果分区数少于消费者数，会导致部分消费者空闲。

**总结来说，Kafka通过‘分区内有序’的设计，配合‘让需要保序的消息拥有相同Key’的生产者策略，在提供高吞吐量的同时，满足了业务上局部的顺序性需求。**

---

### 如何保证消息不丢失

Kafka为了保证消息不丢失，在其内部架构上做了几个核心的设计，这些设计共同构成了其高可靠性的基石。主要体现在以下三个方面：

**1. 冗余机制：多副本（Replication）**

这是最根本的机制。Kafka为每个分区的数据创建多个副本（例如3个），并将这些副本分散在不同的物理服务器（Broker）上。这样，单台机器的宕机或磁盘损坏不会导致数据永久丢失，因为其他副本仍然完好无损。

**2. 一致性协议：ISR（In-Sync Replicas）同步副本集与Leader选举**

光有副本还不够，必须保证副本之间的一致性。Kafka引入了ISR的概念。

- **ISR**是一个动态集合，包含了所有与主副本（Leader）保持数据同步的副本。
- 生产者可以配置为只有当消息被ISR中的所有副本都成功接收后，才认为发送成功（对应`acks=all`）。**这确保了在消息被确认时，已经在多个Broker上完成了持久化。**
- 当Leader副本失效时，Kafka的Controller组件会**严格地从ISR集合中选举出新的Leader**。这个机制至关重要，它防止了数据不一致的副本成为领导者，从而保证了已被生产者确认的消息绝不会因故障切换而丢失。

**3. 持久化存储：顺序写入与日志段（Log Segment）**

- Kafka直接将消息**追加（Append）写入到磁盘的日志文件**中，而不是依赖内存缓存。这是一种顺序写操作，其性能非常高。
- 消息不会被立即删除，而是会根据配置的保留策略（例如保留7天）持久保存在磁盘上。这意味着在保留期内，即使消费者还没有消费，消息也始终安全地存在于磁盘上。

**总结来说，Kafka自身通过‘数据多副本冗余’、‘基于ISR的一致性协议’和‘消息持久化到磁盘’这三项核心设计，从架构层面保证了消息在系统内部不会丢失。**

---

### 如何保证不重复消费

**kafka 出现消息重复消费的原因：**

- 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
- Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。

**解决方案：**

- 消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。

- 将 

  `enable.auto.commit`

   参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：

  什么时候提交 offset 合适？

  - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
  - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。

---

### 如何解决消息积压@



---

## 其他

### Kafka 是推送还是拉取

**Kafka 采用消费者主动拉取的模型。**

- **拉取模式**：Consumer 主动向 Broker 发起请求，询问是否有可用的新消息。如果有，Broker 会将消息返回给 Consumer；如果没有，Consumer 会根据配置等待一段时间或直接返回空结果。

**为什么 Kafka 要选择拉取模式？**

这与 Kafka 的设计目标——**高吞吐量**和**背压处理**——密切相关。

1. **利于批量处理，提高吞吐量**：拉取模式让 Consumer 可以控制请求的时机和大小。Consumer 可以积累一定量的数据请求后，一次拉取一批消息（`max.poll.records`），极大地减少了网络开销，提高了吞吐量。如果是推送模式，Broker 很难决定一次推送多少条消息给不同的 Consumer。
2. **天然处理背压**：拉取模式让 Consumer 可以根据自身的处理能力来消费。如果 Consumer 处理不过来，它可以放慢拉取的频率或暂停拉取，消息会自然地堆积在 Broker 端，而不会将 Consumer 压垮。这在推送模型中很难实现，推送方可能以生产者的高速压垮消费能力不同的消费者。
3. **简化消息交付语义**：拉取模式使得 Kafka 可以轻松实现“至少一次”等语义。Consumer 只有在处理完消息后才会提交 Offset，如果处理失败，只需不提交 Offset，下次还能拉取到相同的信息重试。

**总结来说，Kafka 的拉取模型是其高吞吐、可扩展和鲁棒性设计的关键选择，它将消费速率和控制权完全交给了消费者，从而更好地适应复杂的分布式环境。**

---

### Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？@



----

### 如果有一个消费主题topic-有一个消费组group-topic有10个分区-消费线程数和分区数的关系是怎么样的@



---

# RabbitMQ

## 基础

**RabbitMQ 是一个开源的、基于 AMQP（高级消息队列协议）的消息代理中间件**。它就像分布式系统中的“邮局”，负责接收、存储和转发消息，帮助不同服务之间**异步**、**可靠**地传递数据，同时实现系统间的**解耦**。

---

### **特点**

1. **协议支持**：原生支持 AMQP，同时兼容 MQTT、STOMP 等协议。
2. **灵活路由**：通过 **Exchange（交换机）** 和 **Queue（队列）** 的绑定规则，支持多种消息路由模式（如精确匹配、通配符广播）。
3. **高可靠性**：提供消息持久化、生产者确认、消费者手动ACK等机制，确保消息不丢失。
4. **跨语言**：支持几乎所有主流编程语言（Java、Python、Go等）。

---

### 核心概念

- **Producer (生产者)**：消息的发送方应用程序，负责创建消息并将其发布到 **Exchange**。
- **Consumer (消费者)**：消息的接收方应用程序，负责从 **Queue** 中获取并处理消息。
- **Exchange (交换机)**：**消息的路由中心**。生产者将消息发送到交换机，它负责根据其**类型**和**绑定规则**，将消息路由到一个或多个队列中。**它本身不存储消息**。
- **Queue (队列)**：**消息的缓冲区**，本质上是存储消息的容器。消费者从这里取走消息进行处理。队列是消息的最终目的地。
- **Binding (绑定)**：连接 **Exchange** 和 **Queue** 的**规则**。它告诉交换机应该将哪些消息路由到哪个队列。
- **Connection & Channel (连接和通道)**：
  - **Connection**：一个 TCP 连接，用于连接应用程序和 RabbitMQ Broker。
  - **Channel**：在 Connection 内部建立的**轻量级逻辑连接**。几乎所有操作都在 Channel 中进行。建立 Channel 的开销远小于建立 TCP 连接，实现了连接的复用，避免了频繁建立 TCP 连接的开销。

- **交换机类型 (Exchange Types)**：决定了交换机的路由行为，这是 RabbitMQ 灵活性的核心。
  - **Direct Exchange**：精确匹配，将消息路由到 Binding Key 与 Routing Key **完全一致**的队列。
  - **Fanout Exchange**：广播模式，将消息路由到所有**绑定到该交换机**的队列，**忽略 Routing Key**。
  - **Topic Exchange**：模式匹配，使用通配符（`*`匹配一个词，`#`匹配零或多个词）进行匹配，将消息路由到所有 Binding Key 与 Routing Key **模式匹配**的队列。**最灵活**。
  - **Headers Exchange**：通过消息头部的属性进行匹配（使用较少）。

---

### 底层架构@



---

### **应用场景**

1. **异步处理**：将耗时操作（如发邮件、处理视频）异步化，提升主流程响应速度。
2. **系统解耦**：服务间通过消息通信，而非直接调用，降低依赖，增加灵活性。
3. **流量削峰**：作为缓冲区应对突发请求（如秒杀），保护后端系统不被冲垮。
4. **应用集成**：作为“胶水”连接不同技术栈的系统，实现跨语言通信。

---

### 优势

**RabbitMQ 的核心优势在于其灵活的路由和精准的消息控制，更适合传统业务场景。**

1. **灵活路由**：其 **Exchange 模型**（Direct、Topic、Fanout 等）支持复杂的消息路由规则，能轻松实现发布订阅和精准投递，这是 Kafka 的弱项。
2. **精细控制**：提供**消息优先级、单条消息TTL、死信队列**等功能，能精细化管理每一条消息的生命周期，Kafka 更侧重于批量吞吐。
3. **更低延迟**：采用推模式，**端到端延迟极低**（微秒级），适合对实时性要求高的业务（如任务分发）。
4. **管理友好**：提供功能丰富的**Web管理界面**，便于监控和运维，开箱即用。

**总结：RabbitMQ 是‘智能的消息代理’，擅长业务解耦和复杂路由；Kafka 是‘高速的日志流平台’，擅长吞吐量和数据管道。两者定位不同，根据场景选择。**

---

### 消息模型

RabbitMQ 采用的核心消息模型是 **“智能交换机”模型**。

**这个模型的实现方式可以概括为：生产者将消息发送到交换机，交换机根据预定的规则将消息路由到一个或多个队列，消费者最终从队列中获取消息。**

这个模型通过几个核心组件协同工作来实现：

1. **Producer（生产者）**：负责创建和发送消息。它的任务是将消息发送到 **Exchange**，并指定一个 **Routing Key**。
2. **Exchange（交换机）**：这是整个模型的“大脑”和路由中心。它负责接收生产者的消息，并根据自身的**类型**和与队列之间的**绑定规则**，决定将消息投递到哪些队列中。交换机本身不存储消息。
3. **Queue（队列）**：这是消息的最终目的地和缓冲区，本质上是存储消息的容器。消费者从这里取走消息进行处理。
4. **Binding（绑定）**：这是连接交换机和队列的“路由规则”。它定义了交换机应该根据什么规则将消息转发到哪个队列。
5. **Consumer（消费者）**：负责从**Queue**中获取并处理消息。

**最关键的部分在于交换机的类型，它决定了具体的路由行为：**

- **Direct Exchange**：执行精确匹配，只有当消息的 **Routing Key** 与 **Binding Key** 完全一致时，消息才会被路由到对应的队列。
- **Fanout Exchange**：执行广播，它会将所有消息路由到所有与它绑定的队列，忽略 **Routing Key**。
- **Topic Exchange**：执行模式匹配，它通过通配符（`*`和 `#`）来匹配 **Routing Key** 和 **Binding Key**，从而实现将消息路由到多个符合模式的队列，非常灵活。

**总结来说，** RabbitMQ 的模型通过将**消息的路由逻辑（由Exchange和Binding负责）** 与**消息的存储和消费逻辑（由Queue和Consumer负责）** 分离开，再通过灵活的交换机规则将它们动态连接，从而实现了高度解耦和极其灵活的消息分发能力。

---

### AMQP

“AMQP，全称是**高级消息队列协议**。它是一种开放标准的**应用层协议**，专门为面向消息的中间件设计。它的核心目标是确保不同厂商开发的消息队列产品能够**相互兼容和交互**。

您可以把它理解成消息队列领域的 **HTTP** 或 **TCP/IP**。就像 HTTP 规定了浏览器和服务器如何通信一样，AMQP 严格定义了**消息的格式**、**消息的传输规则**以及**各个组件（如交换机、队列）的行为**。

**AMQP 和 RabbitMQ 的关系是：**

- **AMQP 是协议**，是规则和标准。
- **RabbitMQ 是实现**，是遵循 AMQP 0-9-1 这个版本协议的具体软件。

**AMQP 模型的核心组件（也就是您在 RabbitMQ 中看到的概念）包括：**

1. **消息**：包含有效载荷和属性的数据单元。
2. **生产者**：发送消息的客户端。
3. **消费者**：接收消息的客户端。
4. **交换机**：接收生产者消息并根据规则路由的核心组件。
5. **队列**：存储消息的缓冲区。
6. **绑定**：连接交换机和队列的规则。

**AMQP 的核心价值在于：**

1. **互操作性**：因为遵循统一的开放协议，用 Python 语言写的生产者可以向 RabbitMQ 发送消息，而用 Java 写的消费者可以从中消费，实现了真正的**跨平台和跨语言**。
2. **可靠性**：协议本身定义了诸如**消息确认、事务、持久化**等机制，为构建可靠的消息系统提供了基础。
3. **通用性**：提供了一套统一的概念模型，降低了学习和使用不同消息中间件的成本。

**总结来说，AMQP 是消息队列的‘通用语言’，而 RabbitMQ 是这门语言最流利、最著名的‘使用者’之一。正是因为它遵循了 AMQP 协议，才使其成为了一个如此流行和强大的企业级消息代理。”**

---

## 死信队列、延迟队列、优先级队列

### 死信队列

死信队列是 RabbitMQ 中用于处理‘异常消息’的一种机制。它本身并不是一个特殊的队列类型，而是一个普通队列被用于特定目的。

**1. 什么是死信队列？**

**死信队列** 是一个专门用来存放那些不能被正常消费的消息的队列。这些消息被称为“死信”。

**它的工作流程是：**

- 首先，我们需要预先创建一个普通的队列，并将其绑定到一个交换机上，这个交换机就称为 **死信交换机**。
- 然后，我们在创建业务队列时，通过参数指定：如果本队列有消息变成‘死信’，就将它们自动重新发布到那个指定的死信交换机上。
- 最后，死信交换机会根据规则将这些死信消息路由到死信队列中。

这样，我们就可以从一个统一的地方（死信队列）来监控和处理所有异常消息。

**2. 消息如何成为‘死信’？（导致原因）**

一条消息在以下三种情况下会被标记为‘死信’并被重新路由：

- **消息被消费者拒绝并要求不重新投递**：消费者接收到消息后，调用 `basic.reject`或 `basic.nack`方法，并且设置 `requeue`参数为 `false`，表示“这条消息我处理不了，也别再塞给我了”。此时，消息就会变成死信。
- **消息在队列中存活时间超时**：
  - **消息级别TTL**：生产者发送消息时设置了过期时间。消息在队列中等待的时间超过了这个设定值。
  - **队列级别TTL**：队列本身设置了消息的最大存活时间。任何在该队列中停留过久的消息都会过期。
  - 一旦消息过期，它就会变成死信。
- **队列长度达到上限**：队列在创建时设置了最大长度限制。当队列已满，再有新消息进来时，最早进入队列的那条消息（位于队列头部）会被强制移出，成为死信，以便给新消息腾出空间。

---

### 延迟队列

**延迟队列**是指一种特殊的队列，里面的消息**不会立即被投递给消费者**，而是会在队列中等待一段**预先指定的时间**后，才能被消费者获取和处理。

---

**应用场景**

延迟队列的核心用途是处理**需要定时或延迟触发**的任务，在实际业务中应用极其广泛：

- **订单系统**：用户下单后如果**15分钟未支付**，则自动关闭订单。
- **定时任务**：预约会议开始**前15分钟**，自动发送提醒通知。
- **重试机制**：业务处理失败后，不希望立即重试（可能加重系统负担），而是希望**延迟5分钟**后再进行重试。
- **异步调度**：在特定时间后触发某个操作，如文章定时发布、优惠券定时生效等。

---

**RabbitMQ 如何实现延迟队列？**

RabbitMQ 自身**没有直接提供**延迟队列的功能，但可以通过组合其两个核心特性：**消息TTL** 和 **死信交换机**，来巧妙地实现延迟队列的效果。

**实现原理与步骤：**

1. **创建死信交换机和死信队列**：首先，创建一个普通的交换机作为`死信交换机`，并创建一个普通的队列作为`死信队列`，并将它们绑定起来。这个队列就是我们最终获取延迟消息的地方。
2. **创建延迟队列（本质是缓冲队列）**：创建一个用于实现延迟的“缓冲队列”，并在创建时为其设置两个关键参数：
   - `x-dead-letter-exchange`：指定第一步中创建的`死信交换机`。
   - `x-message-ttl`：设置队列中所有消息的存活时间，**这个时间就是我们想要的延迟时间**（例如 60000 毫秒 = 1 分钟）。
3. **发送消息**：生产者将消息发送到这个“缓冲队列”中。
4. **消息流转过程（核心）**：
   - 消息进入“缓冲队列”后，并不会被消费者消费，而是开始“倒计时”。
   - 当消息的存活时间（TTL）达到设定的延迟时间后，消息就会“死亡”，变成一条**死信**。
   - 由于我们为“缓冲队列”设置了 `x-dead-letter-exchange`，这条死信就会被**自动转发**到指定的死信交换机。
   - 死信交换机将消息路由到最终的死信队列。
   - 此时，真正的消费者从**死信队列**中获取消息并进行处理。

---

### 优先级队列

**优先级队列是一种特殊类型的队列，它允许消息根据预设的优先级被消费，而不是严格遵循默认的先进先出的顺序。优先级高的消息会被优先处理。**

它的实现和用途主要有以下几点：

1. **如何工作**：在 RabbitMQ 中，创建队列时需要通过参数 `x-max-priority`来声明队列支持的最大优先级（通常为0-10）。生产者发送消息时，可以为每条消息设置一个优先级数值，数值越大，优先级越高。
2. **核心用途**：它主要用于处理有紧急程度差异的任务。例如：
   - 在订单系统中，优先处理VIP用户的订单。
   - 在告警系统中，优先处理高危级别的告警消息。
   - 在任务调度中，优先执行重要的后台任务。
3. **需要注意的点**：
   - **性能权衡**：因为Broker需要在内部对消息进行排序，所以大量使用优先级可能会轻微影响吞吐量。
   - **并非绝对抢占**：如果一个消费者正在处理一条低优先级消息，此时一条高优先级消息入队，消费者并不会中断当前的处理。它只会在获取下一条消息时，优先获取高优先级的。

**总结来说，优先级队列是对标准FIFO模型的一个有力补充，适用于需要区分任务处理紧急程度的业务场景。**

---

## 消费顺序、消息可靠、高可用

### 如何保证消费顺序

RabbitMQ本身不提供顺序保证，其灵活的路由模型可能导致消息乱序。需要在架构和消费端做设计。

**核心挑战**：RabbitMQ的多个消费者可能并行从同一个队列拉取消息，导致处理顺序无法保证。

**如何实现：**

1. **单一队列，单一消费者**：最直接的方法是为需要保序的消息组创建一个独占队列，并且该队列**只配置一个消费者**。这牺牲了并发性来换取顺序性。
2. **业务层分组**：如果无法接受单消费者的性能，可以采用“**业务分组**”思路。将需要保序的消息（如同一订单的消息）赋予相同的特征（如相同的订单ID），并通过哈希等方式，确保它们被路由到同一个队列，并由同一个消费者处理。这本质上是在应用层模拟了Kafka的分区概念。

---

### 如何保证消息可靠

RabbitMQ 通过在其消息生命周期的**生产者发送、Broker存储、消费者消费**这三个环节上采取协同措施，来共同保证消息的可靠性。

------

**1. 生产者端：确保消息成功送达Broker**

防止消息在发送过程中丢失。

- **机制一：生产者确认机制**
  - **事务机制**：类似数据库事务，通过 `txSelect`, `txCommit`, `txRollback`实现。**不推荐**，因为性能差（同步阻塞）。
  - **确认机制**：这是**推荐**的方式。生产者通过调用 `confirmSelect`方法将信道设置为 `confirm`模式。之后每发送一条消息，RabbitMQ Broker 会异步回传一个 `ack`确认信号表示已成功接收。如果消息丢失，Broker 会回传 `nack`或直接不回应，生产者可以据此进行重发。
- **机制二：消息持久化**
  - 生产者发送消息时，可以通过设置 `deliveryMode = 2`将消息标记为**持久化**。这样即使RabbitMQ服务器重启，消息也不会丢失。

**2. Broker端：确保消息被安全存储**

防止消息在RabbitMQ服务器中丢失。

- **机制一：消息持久化**
  - 光消息本身持久化还不够，承载它的**队列也必须是持久化的**。在声明队列时，设置 `durable = true`。这样即使RabbitMQ服务重启，队列本身也不会消失。
  - **总结**：必须同时满足 **队列持久化** 和 **消息持久化**，消息才能在服务器重启后幸存。
- **机制二：镜像队列**
  - 这是保证Broker高可用的终极方案。通过搭建RabbitMQ集群，并将队列配置为**镜像队列**。这样队列中的消息会被复制到集群中的多个节点上。即使一个节点宕机，其他节点依然能提供服务，消息不会丢失。

**3. 消费者端：确保消息被成功处理**

防止消息在消费过程中丢失。这是最容易出错的环节。

- **机制：手动确认**
  - **务必关闭自动确认**，设置 `autoAck = false`。
  - 采用**手动确认**模式。消费者只有在业务逻辑被**成功执行完毕后**，再显式调用 `channel.basicAck()`方法向Broker发送确认信号。
  - 如果处理失败或消费者中途宕机，Broker 由于没有收到 `ack`，会将消息**重新放回队列**（或转发给其他消费者），从而消息不会丢失。
  - 这保证了“至少一次”的投递语义。

---

### 如何保证高可用

RabbitMQ 主要通过 **镜像队列** 机制来保证高可用。它的设计目标是：当集群中的某个节点失效时，能够实现**自动故障转移**，确保服务不中断、消息不丢失。

**1. 核心机制：镜像队列**

- **原理**：镜像队列本质上是将队列的副本**同步复制**到集群中的多个节点上。一个队列有一个**主节点**和若干个**镜像节点**。
- **读写操作**：所有写操作（生产者发消息）都首先在主节点上执行，然后主节点会将操作同步到所有镜像节点。读操作（消费者消费）可以由主节点或镜像节点处理（取决于连接）。
- **自动故障转移**：如果主节点所在服务器宕机，RabbitMQ 会**自动从剩余的镜像节点中选举出一个新的主节点**，并重组镜像队列。这个过程对生产者和消费者是透明的，它们会自动重连到新的主节点，从而保证服务不间断。

**2. 实现高可用的前提：集群搭建**

镜像队列是建立在 RabbitMQ 普通集群之上的。因此，实现高可用的第一步是搭建一个多节点的集群。集群中的节点可以共享元数据（如交换机、绑定的定义），但队列内容默认不会复制，这正是镜像队列要解决的问题。

**3. 策略配置：定义镜像规则**

镜像队列的行为通过**策略**来灵活定义。在创建策略时，可以指定：

- **ha-mode**：镜像模式，常用 `all`（同步到所有节点）或 `exactly`（同步到指定数量的节点）。
- **ha-sync-mode**：同步模式，推荐 `automatic`（新节点加入时自动同步消息）。

**4. 与持久化协同工作**

高可用性必须与**消息持久化**结合才能发挥最大效用：

- 将队列声明为**持久化**（Durable）。
- 发送消息时设置 **`deliveryMode=2`**（持久化消息）。
- 这样即使整个集群断电，重启后也能恢复数据和队列结构。

**总结来说，RabbitMQ 的高可用架构是通过‘普通集群+镜像队列+消息持久化’三者协同实现的。其核心是镜像队列的自动主从切换能力，确保了在单点故障时服务的连续性和数据的可靠性。**

---

# RocketMQ

RocketMQ是阿里开源的一款**金融级、高性能的分布式消息和流处理平台**。它在Kafka的设计理念上做了演进，更侧重于**业务消息领域**，提供了更高的可靠性和更丰富的功能。

## 基础

### 特点

1. **金融级事务消息**
   - 提供完整的**二阶段提交**事务消息机制，确保分布式事务的最终一致性
   - 典型场景：支付订单成功后，保证积分增加和库存扣减同时完成或同时回滚
2. **海量消息堆积能力**
   - 采用单一持久化日志结构，支持**万亿级**消息堆积
3. **丰富的消息类型**
   - **顺序消息**：保证同一业务ID（如订单号）的消息严格有序
   - **延迟消息**：内置18个延迟级别（1s/5s/10s...2h）
   - **批量消息**：单次通信可传输多达4MB的消息集合
4. **高可用架构**
   - 多副本机制（主从自动切换）
   - 去中心化的**NameServer**服务发现（对比Kafka依赖ZooKeeper更轻量）
   - 支持多机房部署的同城容灾方案
5. **企业级运维支持**
   - 完善的监控告警体系
   - 消息轨迹追踪功能
   - 丰富的管理控制台

---

### 核心概念

**1. 核心组件（架构层面）**

- **NameServer**：**轻量级的服务发现与路由中心**。所有Broker都会向NameServer注册，客户端（生产者和消费者）也从它这里获取Broker的路由信息。它是**无状态**的，节点之间互不通信，因此非常轻量和稳定，这是与Kafka依赖ZooKeeper的重要区别。
- **Broker**：**消息存储和转发的中继站**。负责接收生产者发送的消息、存储消息，并处理消费者的拉取请求。它是真正存储消息的服务器。
- **Producer**：**消息生产者**，负责产生消息并将它们发送到Broker。
- **Consumer**：**消息消费者**，负责从Broker拉取消息并进行消费处理。

**2. 核心模型（逻辑层面）**

- **Topic**：**消息的主题**，是消息的逻辑分类。生产者将消息发送到指定的Topic，消费者订阅感兴趣的Topic来消费消息。
- **Message Queue**：**消息队列**，是Topic的物理分区。一个Topic可以被划分为多个Message Queue，从而实现分布式存储和水平扩展。**这是实现负载均衡和并行消费的关键**。
- **Tag**：**消息标签**，隶属于Topic，用于对Topic下的消息进行二次细分。消费者可以基于Topic和Tag进行订阅，实现更精细的消息过滤。
- **Offset**：**偏移量**，用于标识Message Queue中的消息位置。消费者通过管理其消费进度（Offset）来决定下一次从哪里开始消费。

**3. 核心机制（功能层面）**

- **生产者组**：同一类生产者的集合。如果某个生产者实例宕机，其他实例可以接替其工作，保证发送高可用。
- **消费者组**：同一类消费者的集合，采用**集群消费**模式。同一个消费者组内的多个消费者实例共同消费一个Topic，每条消息只会被组内的一个消费者消费，从而实现负载均衡。
- **消息模式**：
  - **集群消费**：默认模式，一条消息只会被同一个消费者组内的一个消费者消费。
  - **广播消费**：一条消息会被同一个消费者组内的所有消费者实例消费一次。

---

### 应用场景

RocketMQ 的设计初衷决定了它特别适合以下**对可靠性、顺序性和事务性有高要求**的业务场景：

1. **核心交易链路**：如电商的**订单、支付、库存**系统。这些场景要求消息绝不能丢，且需要保证顺序（如订单状态：创建->付款->发货）。
2. **金融业务**：如**资金清算、交易对账**。这些场景对分布式事务有强需求，RocketMQ 的**事务消息**特性为此提供了完美支持。
3. **异步解耦与削峰填谷**：将耗时的操作（如发短信、扣积分）异步化，提升主流程性能，应对秒杀等突发流量。
4. **数据同步与流计算**：将数据库变更、日志等数据作为消息发布，供下游业务系统（如分析系统、搜索系统）消费，构建实时数据管道。

---

### 优势

1. **对比 Kafka 的优势**：
   - **功能更丰富，更适合业务开发**：提供了开箱即用的**事务消息、延迟消息**等功能，而 Kafka 需要开发者自己基于底层 API 构建，复杂度高。
   - **海量消息堆积能力**：在相同硬件资源下，RocketMQ 的消息堆积能力远超 Kafka，非常适合作为业务系统的“安全缓冲”。
   - **更轻量的协调组件**：使用 **NameServer** 作为服务发现，比 Kafka 依赖的 **ZooKeeper** 更轻量、稳定，运维更简单。
2. **对比 RabbitMQ 的优势**：
   - **更高的吞吐量和扩展性**：集群和分布式设计更为成熟，能轻松应对海量消息场景。
   - **顺序消息和事务消息**：原生支持这些 RabbitMQ 难以实现或实现起来性能不佳的特性。
   - **更好的吞吐量和扩展性**：集群和分布式设计更为成熟，能轻松应对海量消息场景。

---

## 消息

### RocketMQ延时消息的底层原理

RocketMQ 延时消息的底层原理非常巧妙，它并没有采用传统的‘定时器轮询’方案，而是通过 **‘多级 Topic 投递’** 的方式来实现的。

**1. 消息标记与暂存**

当生产者发送一个延时消息（比如延迟1小时）时，消息会被 Broker 接收到。Broker 会识别出这是一个延时消息，并不会立刻将其投递到目标 Topic（比如 `ORDER_CANCEL_TOPIC`），而是根据其延迟级别（如1小时对应第18级），将这条消息**临时存储到一个特殊的内部 Topic**，叫做 `SCHEDULE_TOPIC_XXXX`中与之对应的队列里。

RocketMQ 默认支持18个固定的延迟级别（1s, 5s, 10s, 30s, 1m, 2m ... 2h），每个级别对应 `SCHEDULE_TOPIC_XXXX`中的一个队列。

**2. 定时扫描与重投**

RocketMQ 有一个专门的**定时调度线程**，它会以固定的频率（每秒一次）去扫描所有 `SCHEDULE_TOPIC_XXXX`下的队列。

它会检查每个队列里消息的‘存储时间’，如果发现某条消息的延迟时间已经到了（比如消息存了1小时了），调度线程就会将这条消息从暂存区 **‘重写’** 到它原本的目标 Topic（`ORDER_CANCEL_TOPIC`）中。

**3. 正常消费**

一旦消息被重写到目标 Topic，它就对消费者可见了。消费者就像消费普通消息一样，从目标 Topic 里拉取到这条延迟消息并进行处理。

**可以把它想象成一个‘邮局中的延时包裹处理中心’：**

1. 普通邮件直接分拣派送（普通消息）。
2. 延时邮件被送到一个专门的‘延时货架’（`SCHEDULE_TOPIC`）上，这个货架有好多层（队列），每层代表不同的延迟时间。
3. 有一个工作人员（调度线程）每隔一会儿就去检查一遍‘延时货架’，发现哪个包裹到时间了，就把它拿出来放到‘普通派件区’（目标Topic）。
4. 邮递员（消费者）从‘普通派件区’取走包裹派送。

**这种设计的优点在于：**

- **高性能**：避免了为每条消息创建单独的定时器，开销极大。统一的扫描任务效率非常高。
- **统一处理**：所有延时消息共用一套调度机制，易于管理和维护。

**它的局限性是：**

- **延迟精度**：由于是秒级扫描，延迟精度在秒级。
- **固定延迟级别**：不支持任意时间点的延迟，只能使用预设的级别。虽然可以通过修改配置来自定义级别，但不灵活。

---

## 消费顺序、重复消费、消息堆积、分布式事务

### 如何保证消费顺序

“RocketMQ通过一套‘**串行化**’的机制来保证顺序，这套机制需要生产端和消费端共同配合完成。”

**a. 生产端（Producer）保证顺序发送：**

- **选择队列（MessageQueue）**：生产者必须将**同一组顺序消息**（如同一个OrderId的所有消息）发送到**同一个Topic下的同一个队列（MessageQueue）中**。
- **实现方式**：通常通过自定义`MessageQueueSelector`，并选择相同的排序依据（如OrderId）作为参数，确保相同OrderId的消息总是被路由到同一个队列。
  - 例如：`producer.send(message, new MessageQueueSelector() { ... }, orderId);`

**b. 服务端（Broker）天然支持：**

- RocketMQ的队列（MessageQueue）本身是FIFO（先进先出）的。这意味着，发送到同一个队列的消息，在Broker层会严格按照发送顺序存储。这是实现顺序消费的基础。

**c. 消费端（Consumer）保证顺序消费：**

- 这是最复杂也最关键的一环。为了保证同一个队列的消息被顺序处理，必须采用**顺序消费（Orderly）** 模式。
- **实现方式**：消费者注册一个`MessageListenerOrderly`而不是`MessageListenerConcurrently`。
- **`MessageListenerOrderly`的工作原理**：
  1. **队列锁机制**：Broker会为每个消费组对每个队列加锁（或租约），确保在同一时刻，**一个队列只被一个消费者线程处理**。
  2. **串行拉取**：消费者会串行地向Broker拉取该队列的消息，而不是并行拉取。
  3. **顺序处理**：消费端在消费消息时，会严格遵循队列的FIFO顺序，处理完一条再处理下一条。只有前一条消息消费成功（返回`CONSUME_SUCCESS`），才会继续消费下一条。如果消费失败，它会自动进行**队列内消息重试**（而不是跳到下一条），直到成功或超过重试次数进入死信队列。

---

### 如何避免重复消费

RocketMQ **无法完全避免重复消费**，这是由分布式系统的网络不确定性（如ACK确认失败触发重投）决定的。因此，解决方案不是在MQ层面阻止重复，而是在**消费端通过业务逻辑实现幂等性**，保证重复消费不会导致数据错误。

------

**RocketMQ 产生重复的原因：**

1. **生产者重试**：发送消息后未收到Broker确认，生产者重试可能导致重复消息。
2. **消费者重投**：消费者消费成功后，若ACK确认失败（如网络抖动），Broker会重新投递消息。
3. **负载均衡**：消费者重启或扩容时，部分消息可能被重新分配并重复消费。

------

**解决方案：业务层幂等设计**

**幂等性核心**：无论同一条消息消费多少次，结果与消费一次一致。

常用实现方式：

1. **数据库唯一约束**（最推荐）
   - 将消息中的业务唯一标识（如订单ID）作为数据库主键或唯一索引字段。
   - **效果**：第一次消费插入成功，重复消费因唯一冲突失败。
2. **乐观锁（版本号控制）**
   - 更新数据时，带上版本号条件（如`update table set value=new_value, version=2 where id=xxx and version=1`）。
   - **效果**：重复消费时版本号不匹配，更新失败。
3. **状态机校验**
   - 消费前检查业务状态是否已处理（如订单已是“已支付”状态，则忽略重复的支付消息）。
4. **防重表**
   - 单独建表记录已处理消息的唯一ID（如消息ID或业务ID），消费前先插入防重表，利用主键冲突避免重复。

---

### 如何解决消息堆积

**1. 核心思路：提升消费能力（快速消费）**

这是最根本的解决方案。当出现堆积时，优先考虑如何让消费者更快地处理消息。

- **优化消费逻辑**：检查消费者代码是否存在性能瓶颈，如慢SQL、复杂的业务计算、同步调用第三方接口等。优化这些点能直接提升消费速度。
- **增加消费者实例**：这是最直接、最有效的扩容手段。通过增加**消费者组内的消费者数量**，利用 RocketMQ 的负载均衡机制，让多个消费者并行处理不同队列的消息。**注意：消费者实例数不要超过订阅Topic的读写队列总数**，否则多余的消费者会空闲。
- **增加队列数量**：如果当前队列数已经是瓶颈（例如只有4个队列，最多只能有4个消费者并行消费），可以通过在线运维命令**动态增加队列数**，然后再扩容消费者实例，从而实现更高的并发度。

**2. 辅助思路：控制消息源头（限流降级）**

如果消费速度暂时无法提升，就需要从消息的入口进行控制。

- **生产者限流/降级**：与业务方协商，在系统高峰期暂时关闭一些非核心的消息发送功能，或者降低发送频率，从源头减少消息涌入量。
- **利用 RocketMQ 自身流量控制**：RocketMQ 提供了传输层压力触发的流控机制，当Broker压力过大时，它会快速失败客户端请求，间接减缓生产者发送速度。

---

### 如何实现分布式事务

RocketMQ 通过其独特的**事务消息**机制来实现分布式事务的**最终一致性**。它的设计精髓是**将分布式事务拆解为一个半消息和一个本地事务的执行**，并通过**消息回查**机制来弥补网络不确定性带来的问题。

其核心流程是一个**两阶段提交**的变种，具体步骤如下：

**第一阶段：发送半消息（Prepare Message）**

1. 生产者向 RocketMQ Broker 发送一条**半消息**。这条消息此时对**消费者是不可见**的，它被存储在另一个特殊的 Topic 中。
2. Broker 确认半消息持久化成功，并回复生产者。
3. **这一步的目的是：先确保消息能够成功送达MQ，为后续的补偿操作提供基础。**

**第二阶段：执行本地事务**

1. 生产者开始执行**本地事务**（例如，在数据库里创建订单、扣减库存等）。
2. 生产者根据本地事务的执行结果（成功或失败），向 Broker 发送 **Commit** 或 **Rollback** 指令。

**后续处理：**

- 如果 Broker 收到 **Commit**，则将半消息从特殊 Topic 转移到目标 Topic，这条消息变为**正常消息**，对消费者可见，可以被消费。
- 如果 Broker 收到 **Rollback**，则直接丢弃半消息，流程结束。

**关键机制：事务状态回查**

这是一个非常重要的兜底机制。如果因为网络抖动、生产者宕机等原因，Broker **长时间没有收到**第二阶段的 Commit 或 Rollback 指令，Broker 会主动回调生产者提供一个的接口，询问该半消息的最终状态。

- 生产者需要实现这个回查接口，去检查本地事务的实际执行结果，并返回 Commit 或 Rollback。
- 这个机制确保了即使在极端情况下，消息和本地事务的最终状态也能保持一致，不会出现悬而未决的状态。

**总结来说，RocketMQ事务消息的核心思想是：**

1. **先让消息成功落地**（发半消息）。
2. **再执行本地事务**。
3. **根据本地事务结果决定消息的生死**（Commit/Rollback）。
4. **用事务回查解决异常情况**。

它**不保证强一致性**，而是通过异步确认的方式，保证了业务的**最终一致性**，非常适合像‘下单成功后通知积分服务加积分’这类异步解耦的场景。”

---

# 对比

### Kafka 和 RocketMQ 消息确认机制有什么不同@









### Kafka 和 RocketMQ 的 broker 架构有什么区别@





