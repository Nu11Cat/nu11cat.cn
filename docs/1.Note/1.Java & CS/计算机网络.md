---
title : 计算机网络
order: 7
---

# 网络模型

## `OSI`模型

`OSI`是一种**网络分层模型**，将网络通信过程分为七个层级，主要用于教学和标准化

1. **应用层**：为用户提供网络服务，如浏览网页（HTTP）、邮件（SMTP）、文件传输（FTP）等。
2. **表示层**：负责数据的格式化、加密和解密，确保不同系统之间的数据能够互相理解。
3. **会话层**：管理设备之间的会话，确保通信过程中的数据流顺畅，并负责会话的建立、维护和终止。
4. **传输层**：提供端到端的数据传输，保证数据完整性和可靠性（如TCP、UDP协议）。
5. **网络层**：负责数据的路由选择和传输路径，确保数据从源主机到目的主机（如IP协议）。
6. **数据链路层**：保证数据在物理层上可靠地传输，处理错误检测与纠正（如以太网、MAC地址）。
7. **物理层**：负责数据的实际物理传输，包括电缆、光纤、无线信号等传输媒介。

## `TCP/IP`四层模型

是广泛应用的网络模型，是互联网的基础，可以将 TCP / IP 模型看作是 OSI 七层模型的精简版本

1. **应用层**：专注于提供应用功能，如HTTP、FTP、Telnet、DNS、SMTP    -应用数据
2. **传输层**：为应用层提供网络支持，包括TCP和UDP                                     -TCP头+应用数据
3. **网络层**：负责实际的传输功能，最常用的是IP协议                                     -IP头+TCP头+应用数据
4. **网络接口层**：为网络层提供传输服务，负责在底层网络发送原始数据包  -帧头+IP头+TCP头+应用数据+帧尾

网络接口层的传输单位是帧，IP层的传输单位是包，TCP的传输单位是段，HTTP的传输单位是消息或报文。

## 为什么要分层

 1.各层之间相互独立，不需要知道其他层怎么实现，只需要调用好下层提供的功能就好了

 2.提高了灵活性和可替换性，类似高内聚、低耦合的原则

 3.使得复杂的计算机网络系统变得易于设计，实现和标准化

# HTTP

**HTTP**，即超文本传输协议，用于Web浏览器和服务器之间传输的协议，属于**应用层协议**。定义了浏览器如何请求网页，以及服务器如何响应这些请求。

>超文本：文字、图片、视频等的混合体，有超链接功能，最常见的：HTML

## 状态码

状态码用于描述请求的结果

1xx表示正在处理，2xx表示正常处理完毕，3xx表示需要附加操作，4xx表示服务器无法处理请求，5xx表示服务器处理请求出错

常见如，200 OK表示请求成功，204 No Content表示成功但是没有body数据，206 Partial Content表示资源只是一部分；

301Moved Permanently表示永久重定向，资源不存在了，需改用新的 URL，302 Found表示临时重定向，请求资源还在但是暂时需要另一个URL访问，304 Not Modified不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制；

403表示 Forbidden表示服务器紧张访问，404 Not Found表示请求的资源不存在；

500  Internal Server Error表示服务器内部错误，501表示请求的功能还不支持，502 Bad Gateway：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应，504 Gateway Time-out：为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器收到响应。

## 报文

**请求报文**：

请求行：包含请求方法、请求目标（URL或URI）和HTTP协议版本。

请求头部：包含关于请求的附加信息，如Host、User-Agent、Content-Type等。

空行：请求头部和请求体之间用空行分隔。

请求体：可选，包含请求的数据，通常用于POST请求等需要传输数据的情况。

**响应报文**：

状态行：包含HTTP协议版本、状态码和状态信息。

响应头部：包含关于响应的附加信息，如Content-Type、Content-Length等。

空行：响应头部和响应体之间用空行分隔。

响应体：包含响应的数据，通常是服务器返回的HTML、JSON等内容。

## 请求类型

- GET：用于请求获取指定资源，通常用于获取数据。
- POST：用于向服务器提交数据，通常用于提交表单数据或进行资源的创建。
- PUT：用于向服务器更新指定资源，通常用于更新已存在的资源。
- DELETE：用于请求服务器删除指定资源。
- HEAD：类似于GET请求，但只返回资源的头部信息，用于获取资源的元数据而不获取实际内容。

**GET vs POST**：

GET是从服务器获取指定的资源，请求的参数位置一般写在URL中，参数只允许ASCII，并且浏览器(不是HTTP)对URL长度有限制。GET是安全且幂等的，是“只读”操作，可被浏览器缓存。

POST是根据请求符合(报文body)对指定数据的资源做出处理，POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。POST是不安全不幂等的，是“新增/提交数据”操作，会修改服务器资源，浏览器一般不会缓存POST请求。

注：理论上，任何请求都可以带 body 的，只是规范上GET不带body；并且URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。

>**安全**指请求方法不会破坏/修改服务器资源
>
>**幂等**指多次执行相同的操作结果都相同

## 常见字段

>**HTTP字段（HTTP field）是出现在HTTP请求或响应头部的一组`键: 值`结构，用于携带额外的指令或说明**，帮助服务器和客户端正确处理HTTP消息。

HOST：可以将请求发往「同一台」服务器上的不同网站

Content-Length：表明本次回应的数据长度

Connection：最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用

Content-Type：用于服务器回应时，告诉客户端，本次数据是什么格式

Content-Encoding：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

## 版本

**HTTP/1.0**：每次请求都要重新建立 TCP 连接，效率较低。它的最大问题是连接的**不持久性**。每个请求都必须等待前一个请求的响应完成后才能发送下一个请求。这种模式称为 **请求-响应阻塞**。

**HTTP/1.1**：最突出的特点是简单、灵活和易于扩展、应用广泛和跨平台，缺点是明文传输，不安全，无状态。**无状态**让服务器不用记忆HTTP状态，减轻服务器负担，但是坏处就是进行关联性操作的时候很麻烦，每次都要问身份信息什么的，无状态的解决方法简单的方法是使用Cookie技术，Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。浏览器会自动携带从服务器得到的 Cookie，并在后续请求中发送给服务器。**明文传输**：在传输过程的信息方便阅读，方便调试，但是内容可能被窃听，不安全。**不安全**：明文传输，容易被监听和篡改通信内容；缺乏请求验证，不会验证通信方的身份，容易受到伪造请求的攻击；无法证明报文的完整性。

**性能**：**长连接**（也叫持久连接），减少了重复TCP连接和断开的开销，只要一端没有明确提出断开连接，始终保持TCP连接状态，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。**管道网络传输**：(并没有广泛应用，有队头阻塞问题)建立在长连接的基础上，挂电脑网络传输使在同一个TCP连接里，客户端可以发起多个请求，不需要等前一个请求响应完，减少了整体的响应时间。**队头阻塞**：如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住。

**性能瓶颈**：请求 / 响应头部信息不能压缩，只能压缩Body部分，头部冗长；队头阻塞；没有请求优先级控制；请求只能客户端发起服务器响应。

总之，1.1性能一般。

**HTTP/2**：基于HTTPS，安全性。

**性能改进**：**头部压缩**：协议会消除多个请求里相似的头的部分，即所谓的HPACK算法，客户端与服务器共同维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。**二进制格式**：不再是纯文本形式报文，而是全面采用二进制格式，头信息和数据体统称为帧：头信息帧，数据帧，计算机直接解析二进制报文，增加了效率。**并发传输**：引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接，解决队头阻塞的问题。针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。**服务器推送**：服务器可以主动向客户端发消息，客户端和服务器都可以建立Stream，但是客户端的Stream ID必须是奇数，服务器必须是偶数。

**缺陷**：在TCP层存在“**队头阻塞**”问题：HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。

**HTTP/3**：把HTTP下层的TCP换成了UDP来解决HTTP2的队头阻塞问题。虽然UDP是不可靠传输，但是基于UDP的QUIC协议可以实现类似TCP的可靠传输。

**UDP的QUIC协议**：**无队头阻塞**：类似HTTP/2的 Stream与多路复用概念，在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。不同的是当某个流丢包只会阻塞这个流，因此不存在队头阻塞问题，不同于HTTP/2影响到其他流。**更快的建立连接**：在使用 HTTPS 的情况下，HTTP/1.1 和 HTTP/2 都是先进行 TCP 三次握手，再进行 TLS 握手，最后才开始传输加密的 HTTP 数据。 QUIC内部包含了TLS， 把 TCP 三次握手 + TLS 握手合并成一次。**连接迁移**：当客户端的网络发生变化（如从 Wi-Fi 切换到 5G），连接不会断，可以继续复用原连接进行通信。原理是使用连接ID代替传统的IP+端口标识连接，即便IP/端口改变，只要连接ID不变通信可以继续进行。

## 缓存技术

浏览器/中间服务器在本地保存资源副本，减少重复请求、提示加载速度、节省宽带

有两种实现方式：强制缓存和协商缓存

**强制缓存**：只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边（过期时间是服务器决定的）。是利用HTTP两个响应头部字段实现的，表示资源在客户端缓存的有效期：`Cache-Control`， 是一个相对时间（优先级高，选项多，设置精细，推荐）；`Expires`，是一个绝对时间。

**协商缓存**：协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。成功返回304。基于两种头部实现：**1**，请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现，浏览器用 `If-Modified-Since` 告诉服务器“我上次看到的修改时间”，服务器用 `Last-Modified` 判断资源是否变化，从而决定是否让浏览器继续用旧的；**2**，请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段，用`ETag` 表示“资源版本”，浏览器每次带上旧版本号问服务器“这个版本还有效吗？”，服务器比对后决定是否返回新资源。**`ETag`优先级更高**，因为它可以解决Last-Modified的几个问题：内容没有修改的情况下文件最后修改时间也可能改变；可能有些文件是在秒级以内修改的，而`If-Modified-Since` 能检查到的粒度是秒级的；有些服务器不能精确获取文件的最后修改时间。

注：协商缓存是强制缓存的“备胎”，只有强制缓存失效时才会触发协商缓存流程。

 **`ETag` 实现协商缓存的过程**：

当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 `ETag` 唯一标识，这个唯一标识的值是根据当前请求的资源生成的。当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：如果没有过期，则直接使用本地缓存；如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 `ETag` 唯一标识。

服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：如果值相等，则返回 304 Not Modified，不会返回资源；如果不相等，则返回 200 状态码和资源内容，并在 Response 头部加上新的 `ETag`唯一标识。

如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。

## HTTP如何保存用户状态

HTTP 协议是**无状态的协议**，它本身不会记录客户端的请求状态，每次请求都是独立的。这意味着服务器无法直接知道两个请求是否来自同一个用户。

为了在 HTTP 协议上实现用户状态的保存，通常会借助以下几种机制：

### 方案一

**Session (会话) 配合 Cookie (主流方式)：**

基本流程是这样的：

1. 用户向服务器发送用户名、密码、验证码用于登陆系统。
2. 服务器验证通过后，会为这个用户创建一个专属的 Session 对象（可以理解为服务器上的一块内存，存放该用户的状态数据，如购物车、登录信息等）存储起来，并给这个 Session 分配一个唯一的 `SessionID`。
3. 服务器通过 HTTP 响应头中的 `Set-Cookie` 指令，把这个 `SessionID` 发送给用户的浏览器。
4. 浏览器接收到 `SessionID` 后，会将其以 Cookie 的形式保存在本地。当用户保持登录状态时，每次向该服务器发请求，浏览器都会自动带上这个存有 `SessionID` 的 Cookie。
5. 服务器收到请求后，从 Cookie 中拿出 `SessionID`，就能找到之前保存的那个 Session 对象，从而知道这是哪个用户以及他之前的状态了。

使用 Session 的时候需要注意下面几个点：

- **客户端 Cookie 支持**：依赖 Session 的核心功能要确保用户浏览器开启了 Cookie。
- **Session 过期管理**：合理设置 Session 的过期时间，平衡安全性和用户体验。
- **Session ID 安全**：为包含 `SessionID` 的 Cookie 设置 `HttpOnly` 标志可以防止客户端脚本（如 JavaScript）窃取，设置 Secure 标志可以保证 `SessionID` 只在 HTTPS 连接下传输，增加安全性。

Session 数据本身存储在服务器端。常见的存储方式有：

- **服务器内存**:实现简单，访问速度快，但服务器重启数据会丢失，且不利于多服务器间的负载均衡。这种方式适合简单且用户量不大的业务场景。
- **数据库 (如 MySQL, PostgreSQL)**:数据持久化，但读写性能相对较低，一般不会使用这种方式。
- **分布式缓存 (如 Redis)**:性能高，支持分布式部署，是目前大规模应用中非常主流的方案。

### 方案二

**当 Cookie 被禁用时：URL 重写 (URL Rewriting)**

如果用户的浏览器禁用了 Cookie，或者某些情况下不便使用 Cookie，还有一种备选方案是 URL 重写。这种方式会将 `SessionID` 直接附加到 URL 的末尾，作为参数传递。例如：http://www.example.com/page?sessionid=xxxxxx。服务器端会解析 URL 中的 `sessionid` 参数来获取 `SessionID`，进而找到对应的 Session 数据。

这种方法一般不会使用，存在以下缺点：

- URL 会变长且不美观；
- `SessionID` 暴露在 URL 中，安全性较低（容易被复制、分享或记录在日志中）；
- 对搜索引擎优化 (SEO) 可能不友好。

### 方案三

**Token-based 认证 (如 JWT - JSON Web Tokens)**

这是一种越来越流行的无状态认证方式，尤其适用于前后端分离的架构和微服务。

以 JWT 为例（普通 Token 方案也可以），简化后的步骤如下

1. 用户向服务器发送用户名、密码以及验证码用于登陆系统；
2. 如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT；
3. 客户端收到 Token 后自己保存起来（比如浏览器的 `localStorage` ）；
4. 用户以后每次向后端发请求都在 Header 中带上这个 JWT ；
5. 服务端检查 JWT 并从中获取用户相关信息。

# HTTPS

## HTTP vs HTTPS

主要区别在于安全性，HTTP基于 **TCP** ，不加密，数据在传输过程是明文；HTTPS加密，通过SSL/TLS协议加密，SSL/TLS 位于 **HTTP** 和 **TCP** 之间，在传输过程不可被第三方轻易读取或篡改，HTTPS在TCP三次握手之后还需要SSL/TLS握手。

另外HTTP使用80端口，而HTTPS使用443端口；HTTPS耗费更多服务器资源

### **如何解决了HTTP的问题**

HTTP是明文存储，存在窃听风险，篡改风险，冒充风险。

HTTPS通过信息加密，校验机制，身份证书解决，具体：

**混合加密**：保证信息机密性，解决窃听风险。混合加密即**对称加密**和**非对称加密**：通信建立前采用非对称加密交换会话密钥，通信过程全部使用对称加密加密明文数据。对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。非对称加密使用两个密钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但是速度慢。

>你用锁（非对称加密）把一把钥匙（对称密钥）寄过去，只有朋友能打开锁（只有他有私钥）
>
>接下来你们用这把钥匙通信，聊天内容都上锁（对称加密），别人看不懂。

**摘要算法+数字签名**：摘要算法即哈希函数，哈希值唯一，且无法通过哈希值推导出内容。它可以保证内容不会被篡改，但是不能保证“内容+哈希值”不会被替换，因为缺少对客户端收到的信息是否来自服务器的证明。比如你可以同时伪造请假说明和家长签字来骗请假。那么就需要非对称加密算法解决：主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份吗，加密内容表示内容本身，因为耗费性能，是对哈希值加密。

>原文：我爱Java
>
>摘要：哈希后变成一串64位的码（假设为 `abc123`）
>
>私钥加密：把 `abc123` 用私钥加密生成签名
>
>发出去：把“我爱Java” + 签名一起发出
>
>接收方：
>
>用公钥解密签名 → 得到 `abc123`
>
>对“我爱Java”再哈希 → 也是 `abc123`
>
>二者相同 → OK，没改过，确实是发的人发的

**数字证书**：公钥可能被伪造，所以缺少身份验证的环节。通过一个权威机构证明身份（CA），只要证书可信，那么公钥可信。

>如果 你同时伪造请假说明和家长签字来骗请假的方法 被数字签名解决了，也就是家长和老师分别持有私钥和公钥，但是你也可以掉包两方的公私钥，那么家长可以把个人信息在警察局注册成数字证书「个人信息 + 公钥 + 数字签名」，那么老师拿到证书可以去警察局验证是否合法来判断这个公钥是不是家长的。

## 如何建立连接

SSL/TLS协议流程：1，客户端向服务器索要并验证服务器的公钥，2，双方协商生产「会话秘钥」，3，双方采用「会话秘钥」进行加密通信。前两个阶段就是TLS握手阶段。

TLS握手涉及四次通信，现在常用的密钥交换算法有两种：RSA算法和ECDHE算法。

**TLS 协议建立详细流程**：

1，ClientHello：客户端向服务器发起ClientHello加密通信请求，发送了客户端支持的TLS协议版本 + 客户端生产的随机数(用来生成对话密钥) + 支持的密码套件系列(加密算法)

2，SeverHello：服务器做出响应，发送 确认TLS协议版本(不支持该版本就关闭加密通信) + 服务器生产的随机数(用来生成对话密钥) + 确认密码套件系列 + 服务器的数字证书

3，客户端回应：客户端收到回应后，先通过浏览器/操作系统的CA公钥确认数字证书真实性，随后从数字证书取出服务器公钥，使用它加密报文，向服务器发送 一个随机数(pre-master key,会被服务器公钥加密) + 加密通信算法改变通知(“随后的信息都将用「会话秘钥」加密通信”) + 客户端握手结束通知。同时把之前所有内容的发生的数据做摘要，原来供服务端校验。

双方使用三个随机数用协商的加密算法各自生成本次通信的会话密钥。

4，服务器最后回应：加密通信算法改变通知 + 握手结束通知

至此握手阶段结束，进入加密通信，完全使用HTTP协议，只不过使用会话密钥加密内容。

**CA 签发证书的过程**：1，CA把持有者公钥、用途、颁发者、有效时间等信息打包成一个包，对这些信息进行HASH计算，2，CA使用私钥将该hash值加密，生成Certificate Signature，也就是CA对证书进行了签名，3，将 Certificate Signature 添加在文件证书上，形成数字证书。

**客户端校验服务端的数字证书的过程**：1，客户端使用同样的Hash算法获取证书Hash值H1，2，通常浏览器和操作系统集成了CA公钥信息，浏览器收到证书后可以使用CA公钥解密Certificate Signature，得到哈希值H2，3，对比H1和H2，如果值相同则可信。

**证书信任链问题**：因为我们向CA申请的证书一般不是根证书，而是中间证书。1，当客户端收到证书后，发现签发者不是根证书，那就根据证书的签发者找到是“xx中间证书”，向CA请求中间证书，然后发现“xx中间证书”是“xx根证书CA”签发的，也就是说它是根证书，也就是自签证书。应用软件会检查此证书是否已经预载于根证书清单。如果有根证书，则用根证书公钥验证中间证书，通过后再用中间证书去验证收到的证书，依然通过后就可以信任。

**为什么要有证书链**：为了保证根证书的绝对安全，将根证书隔离，防止根证书失守导致整个信任链路的崩塌。

## 如何保证数据完整性

TLS分为**握手协议**和**记录协议**：握手协议即四次握手，负责协商加密算法和生成对应密钥；记录协议负责保护应用程序数据并验证完整性和来源。

**记录协议**：主要负责消息的压缩，加密，数据认证：1，消息被分割成多个较短的片段,然后分别对每个片段进行压缩；2，压缩后的片段会加上消息认证码(MAC)，这一步是为了保证完整性，及进行数据认证。同时为了防止重放攻击，在计算消息认证码时还加上了片段编码；3，片段再加上消息认证码会一起通过对称密码进行加密；4，经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。5，报文数据将传递到传输控制协议 (TCP) 层进行传输。

## HTTPS一定安全吗(场景题)

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#https-一定安全可靠吗)

## HTTPS如何优化

[3.5 HTTPS 如何优化？ | 小林coding](https://xiaolincoding.com/network/2_http/https_optimize.html#_3-5-https-如何优化)

## 为什么抓包工具能截取 HTTPS 数据？

工作原理与中间人一致，在服务端面前作为客户端，因为服务端不会校验客户端身份；在客户端面前作为服务端，因为它持有客户端的信任，也就是拥有对应域名的私钥。

客户端会往受系统信任的根证书列表导入抓包工具生成的证书，这个证书会被浏览器信任。

## 如何避免被中间人抓取数据

保证电脑安全；不点击证书非法的网站；HTTPS双向认证

**HTTPS双向认证**：一般的HTTPS是单向认证，服务端不会验证客户端身份。双向认证中客户端也有数字证书，并且提供给服务器，服务器要校验客户端身份。

# WebSocket

WebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。WebSocket 协议本质上是应用层的协议，用于弥补 HTTP 协议在持久通信能力上的不足。客户端和服务器仅需一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。

WebSocket继承了TCP 协议的全双工，并且解决了粘包的问题，因为它有明确的消息边界，每条信息都加了帧头，能让接收端准确解析完整消息。

使用场景：适用于需要服务器和客户端频繁交互的大部分场景

## WebSocket vs HTTP

WebSocket 是一种双向实时通信协议，而 HTTP 是一种单向通信协议。并且，HTTP 协议下的通信只能由客户端发起，服务器无法主动通知客户端。

WebSocket 使用 ws:// 或 wss://（使用 SSL/TLS 加密后的协议，类似于 HTTP 和 HTTPS 的关系） 作为协议前缀，HTTP 使用 http:// 或 https:// 作为协议前缀。

WebSocket 可以支持扩展，用户可以扩展协议，实现部分自定义的子协议，如支持压缩、加密等。

WebSocket 通信数据格式比较轻量，用于协议控制的数据包头部相对较小，网络开销小，而 HTTP 通信每次都要携带完整的头部，网络开销较大（HTTP/2.0 使用二进制帧进行数据传输，还支持头部压缩，减少了网络开销）。

## WebSocket vs 长、短轮询

**1.短轮询（Short Polling）**

- **原理**：客户端每隔固定时间（如 5 秒）发起一次 HTTP 请求，询问服务器是否有新数据。服务器收到请求后立即响应。
- **优点**：实现简单，兼容性好，直接用常规 HTTP 请求即可。
- 缺点
  - **实时性一般**：消息可能在两次轮询间到达，用户需等到下次请求才知晓。
  - **资源浪费大**：反复建立/关闭连接，且大多数请求收到的都是“无新消息”，极大增加服务器和网络压力。

**2.长轮询（Long Polling）**

- **原理**：客户端发起请求后，若服务器暂时无新数据，则会保持连接，直到有新数据或超时才响应。客户端收到响应后立即发起下一次请求，实现“伪实时”。
- 优点
  - **实时性较好**：一旦有新数据可立即推送，无需等待下次定时请求。
  - **空响应减少**：减少了无效的空响应，提升了效率。
- 缺点
  - **服务器资源占用高**：需长时间维护大量连接，消耗服务器线程/连接数。
  - **资源浪费大**：每次响应后仍需重新建立连接，且依然基于 HTTP 单向请求-响应机制。

**3. WebSocket**

- **原理**：客户端与服务器通过一次 HTTP Upgrade 握手后，建立一条持久的 TCP 连接。之后，双方可以随时、主动地发送数据，实现真正的全双工、低延迟通信。
- 优点
  - **实时性强**：数据可即时双向收发，延迟极低。
  - **资源效率高**：连接持续，无需反复建立/关闭，减少资源消耗。
  - **功能强大**：支持服务端主动推送消息、客户端主动发起通信。
- 缺点
  - **使用限制**：需要服务器和客户端都支持 WebSocket 协议。对连接管理有一定要求（如心跳保活、断线重连等）。
  - **实现麻烦**：实现起来比短轮询和长轮询要更麻烦一些。

## WebSocket vs SSE

SSE (Server-Sent Events) 和 WebSocket 都是用来实现服务器向浏览器实时推送消息的技术，让网页内容能自动更新，而不需要用户手动刷新。虽然目标相似，但它们在工作方式和适用场景上有几个关键区别：

1. 通信方式:
   - **SSE:** **单向通信**。只有服务器能向客户端（浏览器）发送数据。客户端不能通过同一个连接向服务器发送数据（需要发起新的 HTTP 请求）。
   - **WebSocket:** **双向通信 (全双工)**。客户端和服务器可以随时互相发送消息，实现真正的实时交互。
2. 底层协议:
   - **SSE:** 基于**标准的 HTTP/HTTPS 协议**。它本质上是一个“长连接”的 HTTP 请求，服务器保持连接打开并持续发送事件流。不需要特殊的服务器或协议支持，现有的 HTTP 基础设施就能用。
   - **WebSocket:** 使用**独立的 ws:// 或 wss:// 协议**。它需要通过一个特定的 HTTP "Upgrade" 请求来建立连接，并且服务器需要明确支持 WebSocket 协议来处理连接和消息帧。
3. 实现复杂度和成本:
   - **SSE:** **实现相对简单**，主要在服务器端处理。浏览器端有标准的 EventSource API，使用方便。开发和维护成本较低。
   - **WebSocket:** **稍微复杂一些**。需要服务器端专门处理 WebSocket 连接和协议，客户端也需要使用 WebSocket API。如果需要考虑兼容性、心跳、重连等，开发成本会更高。
4. 断线重连:
   - **SSE:** **浏览器原生支持**。EventSource API 提供了自动断线重连的机制。
   - **WebSocket:** **需要手动实现**。开发者需要自己编写逻辑来检测断线并进行重连尝试。
5. 数据类型:
   - **SSE:** **主要设计用来传输文本** (UTF-8 编码)。如果需要传输二进制数据，需要先进行 Base64 等编码转换成文本。
   - **WebSocket:** **原生支持传输文本和二进制数据**，无需额外编码。

为了提供更好的用户体验和利用其简单、高效、基于标准 HTTP 的特性，**Server-Sent Events (SSE) 是目前大型语言模型 API（如 OpenAI、DeepSeek 等）实现流式响应的常用甚至可以说是标准的技木选择**。



## 如何建立连接

客户端提供HTTP发送一个带有特殊头部的HTTP请求，请求升级为WebSocket协议；服务器如果支持WebSocket会返回101表示协议升级成功；HTTP通道升级为WebSocket连接，后续变成全双工的持久连接。

## 工作过程

WebSocket 的工作过程可以分为以下几个步骤：

1. 客户端向服务器发送一个 HTTP 请求，请求头中包含 `Upgrade: websocket` 和 `Sec-WebSocket-Key` 等字段，表示要求升级协议为 WebSocket；
2. 服务器收到这个请求后，会进行升级协议的操作，如果支持 WebSocket，它将回复一个 HTTP 101 状态码，响应头中包含 ，`Connection: Upgrade`和 `Sec-WebSocket-Accept: xxx` 等字段、表示成功升级到 WebSocket 协议。
3. 客户端和服务器之间建立了一个 WebSocket 连接，可以进行双向的数据传输。数据以帧（frames）的形式进行传送，WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息。
4. 客户端或服务器可以主动发送一个关闭帧，表示要断开连接。另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。

另外，建立 WebSocket 连接之后，通过心跳机制来保持 WebSocket 连接的稳定性和活跃性。

## 消息格式

数据包在WebSocket叫做帧，主要关注以下字段：

**opcode字段**：标志数据帧的类型，比如1是text(String)，2是二进制数据类型([]byte)，8关闭连接

**payload字段**：存放想要传输的数据的长度(单位：字节)

**payload data字段**：真正要传输的数据

# TCP

是面向连接的(必须一对一)、可靠的(保证一个报文一定到达接收端)、基于字节流(粘/拆包的“罪魁祸首”)的传输层通信协议

TCP 连接由**四元组**唯一标识：`源 IP + 源端口 + 目标 IP + 目标端口`

**为什么要有TCP**：IP层是不可靠的，不保证网络包的交付、按序交付、也不保证网络包的数据的完整性。那么就需要上层TCP协议来负责。TCP是一个工作在传输层的可靠数据传输的服务。

**TCP头格式**：序列号（解决网络包乱序问题），确认应答号（解决丢包问题），控制位

## 三次握手

为了确保双方接收和发送能力都正常，建立一条可靠的全双工通信通道

1，客户端向服务器发送SYN报文段，请求建立连接，报文包含客户端生成的初始序列号（seq = x），客户端进入SYN_SENT状态

2，服务器向客户端回复SYN+ACK表示同意连接请求，报文包含确认号（ack = x + 1）和自己的初始序列号（seq = y），服务器进入SYN_RECEIVED 状态

3，客户端再向服务器发送ACK报文段，报文包含（ack = y + 1），客户端进入ESTABLISHED 状态，服务器收到后也进入ESTABLISHED 状态，连接正式建立

注：第三次握手可以顺便携带应用层数据，虽然不常见，但是协议允许；前两次不行，因为未完全建立连接，不安全

### **为什么要三次？**

TCP 采用三次握手建立连接，是为了确保双方都具备发送和接收能力，同时同步双方的初始序列号。更重要的是，第三次握手可以有效防止网络中旧的连接请求被误当成新连接，从而避免服务端错误分配资源，提升连接安全性与可靠性。

### **当握手丢失了会发生什么**：

当第一次握手丢失：当客户端一直收不到第二次握手的回应，会触发超时重传机制，重新发送报文，并且与之前的序列号一样。（每次重传的超时时间是上次的2倍）

当第二次握手丢失：因为第二次丢失对客户端的影响一样，所以也会触发上面的操作。同时对于服务器自然也收不到第三次握手，那么服务端会重传 SYN-ACK 报文，也就是第二次握手的超时重传。

当第三次握手丢失：服务端会重传 SYN-ACK 报文，当服务器重传到最大重传次数就断开连接。ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。

### **为什么每次建立TCP连接初始化的序列号都要求不一样？**

是为了防止旧数据混入新连接、避免重放攻击，并确保每个连接的独立性和安全性。

假设你第一次和服务器建立连接时，序列号为 `0`，并传输了数据。后来，连接关闭了，但是某些数据包在网络中滞留。然后你再次建立连接，如果序列号没有变化，滞留的旧数据可能会被服务器误认为是新连接的数据，导致数据混淆或错误处理。通过随机化序列号，服务器可以确保新连接的序列号与旧连接的序列号不同，从而避免这个问题。

并且攻击者可以猜测和伪造数据包，进行**TCP 重放攻击**。

**ISN序列号是怎么随机产生的？**

TCP 的初始序列号 ISN 是通过**系统内核根据时间和连接信息计算出的伪随机数**，确保每次连接的序列号不同且难以被攻击者预测，从而保障连接的正确性和安全性。

如Linux是   随着时间 每 4 微秒递增的全局计数器   +  基于本地地址、远程地址、端口、时间戳等信息的哈希函数。

## 四次挥手

四次挥手是 TCP 双方各自独立关闭发送通道的过程，确保数据传输完整、有序关闭连接，其中 FIN 表示主动关闭，ACK 表示确认关闭。

1，客户端向服务器发送FIN报文段，表示没有数据要发送，但是还能接收数据，进入FIN_WAIT_1状态

2，服务器向客户端发送ACK报文段，表示知道客户端不发数据了，进入CLOSE_WAIT状态

3，客户端收到ACK报文后进入FIN_WAIT_2状态，此时服务器仍然可能继续发送数据，服务器发送完数据后发送FIN报文，表示没有数据要发了，进入LAST_ACK状态

4，客户端收到FIN后发送ACK确认，进入TIME_WAIT状态，等待2*MSL后关闭连接，服务端收到ACK后也关闭连接

双方都可以主动断开连接，但是主动关闭连接的，才有 TIME_WAIT 状态

**为什么需要四次挥手**：服务端通常要等待完成数据的发送和处理，所以服务端的ACK和FIN一般分开发送，因此是四次挥手。

如果服务器回复ACK的同时，自己也准备断开连接，那么第二三次挥手会合并成一个同时带有ACK和FIN的报文，那么就只需要三次挥手。

**挥手丢失**：

第一次挥手丢失：客户端迟迟收不到服务端ACK，触发超时重传，重发报文，重发次数超过tcp_orphan_retries后会等待一段时间( *=2 )，如果还是没有收到就直接进入close状态

第二次挥手丢失：ACK 报文是不会重传的，客户端重复第一次挥手丢失的操作

注：当客户端处于FIN_WAIT2状态等服务端发送第三次挥手的时候，如果你使用的`close()`关闭连接，`FIN_WAIT2` 状态最多持续 `tcp_fin_timeout` 秒（默认 60 秒）；但如果用 `shutdown()` 只关闭发送方向，`tcp_fin_timeout` 不生效，连接可能永远停在 `FIN_WAIT2` 状态，造成资源泄漏。

第三次挥手丢失：客户端一直停在 `FIN_WAIT2` 状态，等不到第三次挥手，若客户端使用 `close()`，`tcp_fin_timeout` 参数会控制 `FIN_WAIT2` 的最大时长。服务端会在超时重传 `FIN` 报文，重传超出系统设定的上限关闭连接

第四次挥手丢失：客户端收到FIN报文后进入TIME_WAIT状态。在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。但是服务器没有收到ACK报文，重复第三次挥手丢失的操作(重传+断开连接)。这个时候如果客户端又收到了超时重传的FIN，就会重置定时器，等待2MSL时长，断开连接。

#### TIME_WAIT状态

**为什么TIME_WAIT的等待时间是2MSL？**

同样也是**为什么要有TIME_WAIT，不能发送ACK后直接断开？**的原因

MSL是报文最大生存时间；

1，防止因为第四次挥手的ACK丢失导致对方收不到ACK；2， 防止旧连接报文干扰新连接：双方都不再发数据，但是不能保证数据都已经送达，所以会有旧数据在网络中，如果新连接使用了相同的四元组（IP+端口），旧包到达时可能被错误当作新连接的数据，等待2MSL是为了确保数据包彻底过期。

**过多连接处于TIME-WAIT 状态有什么危害？**

占用系统资源；占用端口资源；

**如何优化TIME_WAIT**

[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#time-wait-过多有什么危害)

#### SYN攻击

[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#什么是-syn-攻击-如何避免-syn-攻击)

#### 为什么 TCP 层还需要 MSS ？

IP不是会分片吗，那还要MSS干什么：

IP分片的代价非常大，完整TCP报文被拆成多个多个 IP 数据包，每个包都要独立封装、发送、路由，增加了处理开销；如果一个分片丢了，那么整个报文都要重传。并且分片可能走不同路径，容易丢/乱序；重组由接收端 IP 层完成，增加 CPU 和内存负担；IP 分片可以被利用进行攻击，比如“分片重组攻击”或“DoS 攻击”

所以TCP的MSS的目的就在于主动避免IP分片：发送方会控制每个 TCP 报文段大小不超过对方的 MSS，从而尽量避免 IP 层发生分片。

#### TCP 和 UDP 可以使用同一个端口吗

[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-和-udp-可以使用同一个端口吗)

#### TCP vs UDP

1，连接，TCP传输数据需要先建立连接；UDP不需要连接，即刻传输数据

2，服务对象，TCP一对一；UDP支持一对一，一对多，多对多

3，可靠性，TCP是可靠交付数据的，确保无差错 不丢失 不重复 按序到达；UDP是尽可能交付，不保证可靠（但是可以改造，比如QUIC）

4，拥塞控制、流量控制，TCP有拥塞控制和流量控制机制，保证数据的安全性；但是UDP都没有，网络非常拥堵也不影响UDP发送速率

5，首部开销，TCP首部较长，有一定开销；UDP首部只有8字节且固定不变

6，传输方式，TCP是流式传输，没有边界，但保证顺序；UDP是一个包一个包发送，有边界但是可能丢包和乱序

7，分片不同，TCP如果数据大小大于MSS，会在传输层分片，目标机也会在传输层组装，中途丢失一个只需要传输缺失的；UDP如果数据大小大于MSS，流程一样但是都是在IP层

8，应用，TCP常用于FTP文件传输，HTTP/HTTPS；UDP常用于较少通信，视频等多媒体通信，广播通信

# UDP



# IP

网络号

主机号

子网掩码

# 其他

## PING

PING 命令是一种常用的网络诊断工具，经常用来测试网络中主机之间的连通性和网络延迟。

PING 命令的输出结果通常包括以下几部分信息：

1. **ICMP Echo Request（请求报文）信息**：序列号、TTL（Time to Live）值。
2. **目标主机的域名或 IP 地址**：输出结果的第一行。
3. **往返时间（RTT，Round-Trip Time）**：从发送 ICMP Echo Request（请求报文）到接收到 ICMP Echo Reply（响应报文）的总时间，用来衡量网络连接的延迟。
4. **统计结果（Statistics）**：包括发送的 ICMP 请求数据包数量、接收到的 ICMP 响应数据包数量、丢包率、往返时间（RTT）的最小、平均、最大和标准偏差值。

如果 PING 对应的目标主机无法得到正确的响应，则表明这两个主机之间的连通性存在问题（有些主机或网络管理员可能禁用了对 ICMP 请求的回复，这样也会导致无法得到正确的响应）。如果往返时间（RTT）过高，则表明网络延迟过高。

**工作原理**

PING 基于网络层的 **ICMP（Internet Control Message Protocol，互联网控制报文协议）**，其主要原理就是通过在网络上发送和接收 ICMP 报文实现的。

ICMP 报文中包含了类型字段，用于标识 ICMP 报文类型。ICMP 报文的类型有很多种，但大致可以分为两类：

- **查询报文类型**：向目标主机发送请求并期望得到响应。
- **差错报文类型**：向源主机发送错误信息，用于报告网络中的错误情况。

PING 用到的 ICMP Echo Request（类型为 8 ） 和 ICMP Echo Reply（类型为 0） 属于查询报文类型 。

- PING 命令会向目标主机发送 ICMP Echo Request。
- 如果两个主机的连通性正常，目标主机会返回一个对应的 ICMP Echo Reply。

## DNS

DNS（Domain Name System）域名管理系统，是当用户使用浏览器访问网址之后，使用的第一个重要协议。DNS 要解决的是**域名和 IP 地址的映射问题**。

目前 DNS 的设计采用的是分布式、层次数据库结构，**DNS 是应用层协议，它可以在 UDP 或 TCP 协议之上运行，端口为 53** 。

### DNS 服务器有哪些？根服务器有多少个

DNS 服务器自底向上可以依次分为以下几个层级(所有 DNS 服务器都属于以下四个类别之一):

- 根 DNS 服务器。根 DNS 服务器提供 TLD 服务器的 IP 地址。目前世界上只有 13 组根服务器，我国境内目前仍没有根服务器。
- 顶级域 DNS 服务器（TLD 服务器）。顶级域是指域名的后缀，如`com`、`org`、`net`和`edu`等。国家也有自己的顶级域，如`uk`、`fr`和`ca`。TLD 服务器提供了权威 DNS 服务器的 IP 地址。
- 权威 DNS 服务器。在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的 DNS 记录，这些记录将这些主机的名字映射为 IP 地址。
- 本地 DNS 服务器。每个 ISP（互联网服务提供商）都有一个自己的本地 DNS 服务器。当主机发出 DNS 请求时，该请求被发往本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 层次结构中。严格说来，不属于 DNS 层级结构

世界上并不是只有 13 台根服务器，这是很多人普遍的误解，网上很多文章也是这么写的。实际上，现在根服务器数量远远超过这个数量。最初确实是为 DNS 根服务器分配了 13 个 IP 地址，每个 IP 地址对应一个不同的根 DNS 服务器。然而，由于互联网的快速发展和增长，这个原始的架构变得不太适应当前的需求。为了提高 DNS 的可靠性、安全性和性能，目前这 13 个 IP 地址中的每一个都有多个服务器，截止到 2023 年底，所有根服务器之和达到了 1700 多台，未来还会继续增加。

### DNS解析过程



### DNS 劫持

DNS 劫持是一种网络攻击，它通过修改 DNS 服务器的解析结果，使用户访问的域名指向错误的 IP 地址，从而导致用户无法访问正常的网站，或者被引导到恶意的网站。DNS 劫持有时也被称为 DNS 重定向、DNS 欺骗或 DNS 污染。

## 从输入`URL`到界面展示

1，对URL解析，确定服务器主机名和请求路径，生成完整HTTP请求

2，查询服务器域名对应的IP地址：也就是域名解析，浏览器检查本地，操作系统检查其DNS缓存，查询本地DNS服务器，递归查询（根DNS服务器-顶级域DNS服务器-权威DNS服务器），返回该域名对应的IP地址给浏览器

3.建立TCP连接：浏览器通过操作系统的Socket接口向目标IP发起TCP连接，TCP三次握手

4.生成HTTP请求报文：请求行、请求头、请求体

5.发送HTTP请求：浏览器通过建立的TCP连接将HTTP请求报文发送到目标服务器。在此过程中，HTTP请求报文会被传递给下层的TCP协议，TCP会将其封装成数据包，并通过**IP层**为其加上IP头。

6.网络层(IP层)的封装与转发：在此过程中，HTTP请求报文会被传递给下层的TCP协议，TCP会将其封装成数据包，并通过**IP层**为其加上IP头。

7.数据链路层(MAC层)：数据包到达目标设备所在网络时，**路由器**通过ARP（地址解析协议）查找目标设备的MAC地址。如果目标设备在同一局域网内，路由器通过ARP获取目标设备的MAC地址，并将IP包封装成以太网帧。交换机使用MAC地址表，将帧转发到正确的端口，确保数据到达目标主机。

8.目标服务器接收数据：目标服务器解析**MAC头**、**IP头**，然后解析**TCP头**来获取数据，服务器检查TCP段的目的端口号，以确定该数据是由哪一个应用程序处理。服务器应用程序（如Web服务器）提取出HTTP请求报文，开始处理请求。

9.服务器生成HTTP响应报文：响应行、响应头、响应体

10.服务器通过TCP连接返回HTTP响应

11.浏览器接收响应，解析HTTP头部，处理响应体内容，渲染网页

12.关闭连接（HTTP/1.1，连接可能保持一段时间但最终会被关闭），TCP四次挥手关闭连接

## URI vs URL

## JWT

## Cookie 和 Session 有什么区别？
